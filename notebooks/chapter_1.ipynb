{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNZK+ttqeceqBoJ9d356tmb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**AI ACCOUNTING CHAPTER 1: CHATBOTS**\n","\n","---"],"metadata":{"id":"cnQK8yTVMAhC"}},{"cell_type":"markdown","source":["##0.REFERENCE"],"metadata":{"id":"tw2-7uYoMGHg"}},{"cell_type":"markdown","source":["https://claude.ai/share/95ec5c52-f6e9-42ca-8837-2ab1d60c22a6"],"metadata":{"id":"axSMA0YpNnYX"}},{"cell_type":"markdown","source":["##1.CONTEXT"],"metadata":{"id":"4LFo5LtiMIff"}},{"cell_type":"markdown","source":["**Introduction: AI for Audit and Accounting – Building Professional-Grade Controls from Day One**\n","\n","**The Objective: Teaching Responsible AI Use Through Hands-On Practice**\n","\n","This notebook has a dual purpose that sets it apart from typical AI tutorials. First, it teaches you how to use Claude AI for practical drafting tasks common in accounting and audit work – workpaper narratives, internal memos, client emails, control descriptions, and document requests. Second, and equally important, it teaches you how to use AI responsibly by building comprehensive governance, documentation, and quality control mechanisms from the very beginning.\n","\n","Most introductions to AI tools focus exclusively on capability: \"Here's what the tool can do, here's how to write prompts, here's how to get good results.\" This notebook takes a fundamentally different approach. It starts with the assumption that if you're using AI for professional work – work that could be reviewed by supervisors, referenced in client deliverables, or examined during quality control – then capability without governance is worse than useless. It's dangerous.\n","\n","The objective is not just to make you proficient with AI tools, but to make you professionally responsible in your use of those tools. By the end of this notebook, you won't just know how to get Claude to draft a workpaper narrative. You'll know how to do it in a way that creates an audit trail, documents limitations, flags risks automatically, protects confidential information, and produces outputs that could withstand scrutiny from a partner, quality control reviewer, or regulator.\n","\n","This is AI use designed for professional accountability, not casual experimentation.\n","\n","**Why This Matters: The Gap Between Consumer AI and Professional AI**\n","\n","You may already use ChatGPT, Claude, or similar tools for personal tasks – drafting emails, brainstorming ideas, summarizing articles, or explaining concepts. Those consumer uses are valuable and appropriate. But professional use in accounting and audit is fundamentally different in several critical ways.\n","\n","In consumer use, you're the only stakeholder. If the AI makes a mistake, you catch it or you don't, but the consequences affect only you. In professional use, your work affects clients, firms, colleagues, and potentially the public. The stakes are higher and the responsibility is shared.\n","\n","In consumer use, there's no documentation requirement. You can have a conversation with AI, use the insights, and move on without creating any permanent record. In professional use, material AI assistance should be documented, particularly if outputs contribute to client deliverables or audit evidence.\n","\n","In consumer use, confidentiality is personal preference. You decide what information you're comfortable sharing with an AI service. In professional use, confidentiality is a binding obligation. Professional standards, firm policies, and client agreements restrict what information can be processed through external services.\n","\n","In consumer use, verification is optional. If you're using AI to draft a personal email, you might quickly scan it and send it without deep review. In professional use, verification is mandatory. Outputs must be reviewed, checked, and approved by qualified humans before any reliance.\n","\n","This notebook bridges the gap between consumer AI use (which many of you already do) and professional AI use (which requires additional controls, documentation, and safeguards).\n","\n","**The Basic Structure: From Setup to Practice to Documentation**\n","\n","The notebook follows a logical progression across ten cells, moving from foundational concepts through tool building to hands-on practice and final documentation.\n","\n","**Cells 1-3 establish the foundation.** Cell 1 provides orientation and sets expectations about what AI can and cannot do safely in accounting and audit contexts. Cell 2 creates the working directory structure. Cell 3 configures your secure connection to Claude with appropriate model settings for professional drafting work.\n","\n","**Cells 4-6 build the governance infrastructure.** Cell 4 creates the documentation system – timestamps, hashes, logs, and manifests that form your audit trail. Cell 5 builds confidentiality protections through automated redaction of sensitive data. Cell 6 creates the core AI conversation function with strict output requirements, automated risk detection, and comprehensive logging.\n","\n","**Cell 7 prepares practice scenarios.** Four carefully designed mini-cases spanning financial statement audits, SOX/ICFR work, tax and technical accounting, and training development. These cases demonstrate appropriate AI use across different practice areas.\n","\n","**Cells 8-9 move to execution and practice.** Cell 8 runs all four mini-cases, saves outputs in multiple formats, and generates a quality summary. Cell 9 provides an interactive exercise where you use the system with your own scenario, experiencing the full workflow firsthand.\n","\n","**Cell 10 completes the documentation package.** It creates a comprehensive README, generates a file inventory, bundles everything into a ZIP archive, and provides a final checklist confirming all governance components are present.\n","\n","This structure deliberately mirrors professional workflow: understand the scope, configure your tools, build quality controls, practice on examples, apply to real situations, and document comprehensively.\n","\n","**Why Casual Chatbot Users Should Care About Controls**\n","\n","You might think: \"I just want to draft a workpaper narrative more quickly. Why do I need all this governance overhead? Why can't I just ask Claude to write it and move on?\"\n","\n","The answer lies in a fundamental principle that appears throughout this notebook: capability increases risk, which demands increased controls. When you use AI casually for personal tasks, the capability is limited (drafting assistance) and the risk is low (only affects you). But when you use AI for professional work, even simple drafting, the risks multiply.\n","\n","**Risk of confidentiality breach:** Accidentally sending client-identifying information to external AI services violates professional standards and potentially contractual obligations.\n","\n","**Risk of hallucination:** AI confidently stating incorrect accounting standards, mischaracterizing procedures, or inventing facts that sound plausible but are wrong.\n","\n","**Risk of over-reliance:** Treating AI outputs as verified work rather than drafts requiring human review and approval.\n","\n","**Risk of inadequate documentation:** Using AI materially but failing to document it, creating problems if the work is reviewed or questioned later.\n","\n","**Risk of scope creep:** Starting with simple drafting but gradually relying on AI for judgments, conclusions, or technical analysis beyond its appropriate scope.\n","\n","The controls in this notebook – redaction, strict output schemas, automated risk flagging, comprehensive logging, mandatory disclaimers, and audit trails – exist to manage these risks systematically rather than relying on you to remember every safeguard every time.\n","\n","Think of it this way: you wouldn't audit financial statements without a documented testing plan, wouldn't sign a tax return without review procedures, wouldn't issue an opinion without appropriate evidence. Similarly, you shouldn't use AI for professional work without appropriate controls. The governance mechanisms in this notebook make responsible AI use the path of least resistance.\n","\n","**Key Lessons and Ideas to Take Away**\n","\n","**Lesson 1: Level 1 AI is powerful but narrowly scoped.** Chatbots excel at drafting and formatting from provided facts. They do not verify facts, perform audit procedures, or create audit evidence. Understanding this boundary is essential for safe use.\n","\n","**Lesson 2: Structure matters more than content.** Requiring strict JSON outputs with mandatory sections (facts, assumptions, open questions, risks, verification status) creates transparency and prevents the AI from hiding gaps or overstepping boundaries.\n","\n","**Lesson 3: Redaction is necessary but imperfect.** Automated tools help protect confidentiality, but professional judgment remains essential. Always think before pasting, even with redaction tools available.\n","\n","**Lesson 4: Documentation is not optional overhead.** The audit trail – logs, hashes, manifests, risk registers – enables review, supports quality control, and demonstrates professional responsibility. It's as essential as the AI outputs themselves.\n","\n","**Lesson 5: Risk identification is ongoing.** Automated checks flag common problems (missing open questions, authority citations), but human reviewers must evaluate context-specific risks that no automated system can detect.\n","\n","**Lesson 6: \"Not verified\" is non-negotiable.** Every AI output remains unverified until a qualified human checks it. Never bypass this requirement, regardless of how good the output looks.\n","\n","**Lesson 7: Reproducibility and traceability matter.** Professional work should be explicable and, to the extent possible, reproducible. Configuration hashes, environment fingerprints, and comprehensive logs enable this.\n","\n","**Lesson 8: The governance-to-work ratio is correct.** If governance takes more time than the AI interaction itself, that's appropriate. Professional AI use is mostly governance, with AI interaction as a small component.\n","\n","**The Broader Context: Building a Foundation**\n","\n","This notebook is Chapter 1 of a larger collection teaching AI use across increasing capability levels. Future notebooks will cover extended context (Level 2), multi-turn conversations (Level 3), tool use and retrieval (Level 4), and agentic workflows (Level 5). Each level introduces new capabilities – and new risks demanding additional controls.\n","\n","Starting with Level 1 and its comprehensive governance framework establishes the foundation. As capabilities increase across future levels, you'll build on these foundational controls rather than starting from scratch. The principles of redaction, structured outputs, risk flagging, and comprehensive documentation apply at every level.\n","\n","By mastering Level 1 governance now, you prepare yourself for responsible use of more powerful AI capabilities later.\n","\n","**Your Path Forward**\n","\n","Work through this notebook cell by cell, reading the descriptions, running the code, examining the outputs, and completing the user exercise. Pay attention not just to what the AI produces, but to how the governance systems document, check, and control that production.\n","\n","When you finish, you'll have both capability (you can use Claude for professional drafting) and responsibility (you can do so with appropriate controls). That combination – capability plus responsibility – is what professional AI use requires.\n","\n","The future of accounting and audit will involve AI tools extensively. The question is not whether AI will be used, but whether it will be used professionally – with appropriate governance, documentation, and accountability. This notebook teaches you how to be on the right side of that question from day one."],"metadata":{"id":"d87jHEpQWdBm"}},{"cell_type":"markdown","source":["##2.LIBRARIES AND ENVIRONMENT"],"metadata":{"id":"HzSSYRQ0MKs8"}},{"cell_type":"code","source":["!pip -q install -U anthropic\n","\n","import json, os, re, datetime, hashlib, platform, textwrap, subprocess\n","from pathlib import Path\n","\n","RUN_TS = datetime.datetime.now(datetime.UTC).strftime(\"%Y%m%dT%H%M%SZ\")\n","RUN_DIR = Path(f\"/content/ai_audit_ch1_runs/run_{RUN_TS}\")\n","DELIVERABLES_DIR = RUN_DIR / \"deliverables\"\n","DELIVERABLES_DIR.mkdir(parents=True, exist_ok=True)\n","\n","print(\"Run directory:\", str(RUN_DIR))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nG72GUYzl3yn","executionInfo":{"status":"ok","timestamp":1768143951216,"user_tz":360,"elapsed":3428,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"90fd7a3b-6ebe-4b63-b89a-dbf7cd98debb"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Run directory: /content/ai_audit_ch1_runs/run_20260111T150551Z\n"]}]},{"cell_type":"markdown","source":["##3.CONNECTION WITH CLAUDE"],"metadata":{"id":"STtjBQgwMNHi"}},{"cell_type":"markdown","source":["###3.1.OVERVIEW"],"metadata":{"id":"ShWjt_vyMO17"}},{"cell_type":"markdown","source":["**Cell 3: Setting Up Your Connection to Claude (The AI Brain)**\n","\n","**What This Cell Does**\n","\n","Cell 3 establishes the connection between your Google Colab notebook and Anthropic's Claude AI service. Think of this as setting up a secure phone line to call an expert consultant – except this consultant is an artificial intelligence system designed to help with professional writing tasks.\n","\n","This cell performs three critical functions: it installs the necessary software to communicate with Claude, retrieves your private API key (your personal password), and configures the AI model settings that control how Claude responds to your requests.\n","\n","**Understanding API Keys (Your Private Password)**\n","\n","An API key is like a credit card number for accessing cloud services. It's your unique identifier that tells Anthropic \"this person is authorized to use Claude, and their account should be charged for the usage.\"\n","\n","API keys should NEVER be written directly in code because if someone steals your key, they can use Claude on your account and you'll pay for it. Google Colab provides a secure \"Secrets\" feature to store sensitive information safely.\n","\n","**How to set up your API key:**\n","Look at the left sidebar in Colab, find the key icon, click \"Add new secret,\" name it exactly ANTHROPIC_API_KEY, paste your key from your Anthropic account, and toggle the switch to allow access.\n","\n","**The Three Configuration Settings**\n","\n","**MODEL:** We use \"claude-sonnet-4-5-20250929\" which is the balanced version of Claude – smart enough for professional drafts but cost-effective. Think of it as hiring a competent senior associate rather than an expensive partner.\n","\n","**TEMPERATURE (0.2):** This controls creativity versus consistency on a scale from 0 to 1. We use 0.2 (low) because accounting and audit work needs reliability and standardized language, not creative experimentation. At this setting, Claude behaves like a reliable staff member who consistently follows firm standards.\n","\n","**MAX_TOKENS (1200):** This limits response length to roughly 800-1,000 words (about 2 pages). This is perfect for workpaper sections, memos, or emails – it controls costs and forces concise, focused responses that fit standard firm templates.\n","\n","**Why This Matters**\n","\n","By the end of this cell, you have a working, secure connection to Claude with settings optimized for professional accounting and audit drafting work."],"metadata":{"id":"n_uMwdv8MRcU"}},{"cell_type":"markdown","source":["###3.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"Xml9f9GoMR7J"}},{"cell_type":"code","source":["!pip -q install anthropic\n","import anthropic\n","import os\n","from google.colab import userdata\n","\n","ANTHROPIC_API_KEY = userdata.get('ANTHROPIC_API_KEY')\n","os.environ[\"ANTHROPIC_API_KEY\"] = ANTHROPIC_API_KEY\n","\n","MODEL = \"claude-sonnet-4-5-20250929\"\n","TEMPERATURE = 0.2\n","MAX_TOKENS = 1200\n","\n","key_loaded = bool(os.environ.get(\"ANTHROPIC_API_KEY\"))\n","print(\"API key loaded:\", \"yes\" if key_loaded else \"no\")\n","print(\"Model:\", MODEL)\n","\n","if not key_loaded:\n","    raise ValueError(\n","        \"Missing ANTHROPIC_API_KEY.\\n\"\n","        \"In Colab: left sidebar → Secrets (key icon) → add ANTHROPIC_API_KEY.\\n\"\n","        \"Then re-run Cell 3.\"\n","    )\n","\n","client = anthropic.Anthropic(api_key=os.environ[\"ANTHROPIC_API_KEY\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mCo_9bm0ksEe","executionInfo":{"status":"ok","timestamp":1768143962466,"user_tz":360,"elapsed":7194,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"c17a67ac-6c4b-48c7-e48d-218cdcb5882e"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["API key loaded: yes\n","Model: claude-sonnet-4-5-20250929\n"]}]},{"cell_type":"markdown","source":["##4.THE AUDIT TRAIN INFRASTRUCTURE"],"metadata":{"id":"zSjFjeDuMaZn"}},{"cell_type":"markdown","source":["###4.1.OVERVIEW"],"metadata":{"id":"6OWXlpZoMcHa"}},{"cell_type":"markdown","source":["**Cell 4: Building the Audit Trail Infrastructure (Governance and Documentation)**\n","\n","**What This Cell Does**\n","\n","Cell 4 creates the entire governance and documentation system for this notebook. Think of it as building a filing cabinet with labeled folders before you start working – except this filing cabinet automatically tracks everything you do, creates timestamps, generates unique identifiers, and ensures you can prove exactly what happened during each session.\n","\n","This cell establishes the foundation for professional-grade auditability, traceability, and reproducibility. These three concepts are fundamental to any work that might be reviewed, audited, or used as evidence of procedures performed.\n","\n","**The Core Functions: Your Documentation Toolkit**\n","\n","The cell creates several utility functions that handle routine documentation tasks automatically:\n","\n","**now_iso()** generates timestamps in a standardized international format. Every action in this notebook gets stamped with the exact date and time it occurred, in a format that works across all time zones and computer systems.\n","\n","**sha256_text()** creates unique fingerprints (called hashes) of text. Imagine taking a document and generating a unique 64-character code that represents its exact content. If even a single letter changes, the hash changes completely. This proves content hasn't been altered.\n","\n","**write_json() and append_jsonl()** save structured data to files in a format that both humans and computers can read. JSON is like a universal filing system that preserves relationships between pieces of information.\n","\n","**get_env_fingerprint()** captures details about your computing environment: which version of Python you're using, what packages are installed, what operating system you're running. This matters because AI outputs can sometimes vary slightly based on software versions. Documenting your environment means someone can recreate your exact setup later.\n","\n","**Why Configuration Hashing Matters**\n","\n","The cell creates a BASE_CONFIG object that documents every important setting for this notebook: what project you're working on, which AI model you're using, what temperature setting you selected, and what governance controls are in place.\n","\n","Then it calculates a SHA256 hash of this entire configuration. This hash becomes part of your RUN_ID (the unique identifier for this session). Here's why this matters:\n","\n","If you run this notebook today and get certain results, then someone changes the configuration and runs it next week, the RUN_ID will be different. This immediately signals \"different settings were used\" and prevents confusion about why outputs might differ.\n","\n","**The Three Core Logs**\n","\n","The cell initializes three critical documentation files:\n","\n","**run_manifest.json:** This is like the cover page of a workpaper binder. It records who created this run, when it was created, what configuration was used, and what computing environment was active. Every run gets its own manifest. If you need to explain your work six months later, this file tells the complete story of how this session was configured.\n","\n","**prompts_log.jsonl:** This becomes your conversation log with Claude. Every time you ask Claude to draft something, the cell records what you asked (the prompt), what Claude responded, and hash values for both. The \".jsonl\" format means each interaction is recorded as a separate line, making it easy to review individual exchanges. Importantly, this log contains REDACTED versions of prompts – client-sensitive data has been removed before logging.\n","\n","**risk_log.json:** This maintains a running register of identified risks. Every output from Claude gets automatically evaluated for risks like potential confidentiality breaches, possible hallucinations (invented facts), or missing information. This log aggregates all risk flags across all tasks in the session.\n","\n","**Understanding the RUN_ID**\n","\n","Every time you execute this notebook, it generates a unique RUN_ID combining a timestamp and the configuration hash. For example: \"20260111T150551Z_11fdf22919\"\n","\n","The first part (20260111T150551Z) tells you this run happened on January 11, 2026 at 15:05:51 UTC. The second part (11fdf22919) is the first 10 characters of the configuration hash.\n","\n","This RUN_ID appears on every file created during the session, making it easy to track which outputs came from which run. In a professional environment, you'd reference this RUN_ID in your workpapers just like you'd reference a document number.\n","\n","**The Governance Philosophy**\n","\n","Notice the BASE_CONFIG includes a controls section with this principle: \"capability ↑ ⇒ risk ↑ ⇒ controls ↑\"\n","\n","This means: as AI capabilities increase, risks increase, therefore controls must increase proportionally. This notebook embodies that philosophy by implementing strong controls even for relatively simple AI use (Level 1 drafting).\n","\n","The controls documented include data minimization (redact by default), no invented authority (don't fabricate standards citations), structured outputs (require consistent format), human review (never auto-approve AI outputs), and comprehensive audit trails.\n","\n","**Why This Infrastructure Matters**\n","\n","Imagine you're a reviewer six months from now, looking at a workpaper that says \"AI-assisted draft.\" You need to answer: What did the AI actually do? What inputs did it receive? What outputs did it produce? Were there any red flags? Can I trust this work?\n","\n","This cell ensures you can answer all those questions. The infrastructure it builds is designed for professional accountability – the same standard you'd apply to any work that might be reviewed by senior staff, quality control, regulators, or external auditors.\n","\n","The pip_freeze.txt file it creates lists every Python package installed, with exact version numbers. If someone needs to recreate your environment a year from now, they have the exact recipe.\n","\n","**What You See When This Cell Runs**\n","\n","The cell prints the file paths of the three logs it creates, the deliverables directory where outputs will be saved, and your unique RUN_ID. This confirmation lets you verify the infrastructure is in place before you start any actual AI work.\n","\n","This cell exemplifies professional-grade AI governance: comprehensive documentation, unique identifiers, environment tracking, and risk logging – all automated so you can focus on the substantive work while the audit trail builds itself."],"metadata":{"id":"ARQ8-ZJDoU4I"}},{"cell_type":"markdown","source":["###4.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"GvnsRIc6Mefx"}},{"cell_type":"code","source":["def now_iso() -> str:\n","    return datetime.datetime.now(datetime.UTC).replace(microsecond=0).isoformat() + \"Z\"\n","\n","def sha256_text(s: str) -> str:\n","    return hashlib.sha256(s.encode(\"utf-8\")).hexdigest()\n","\n","def write_json(path: Path, obj: dict):\n","    path.parent.mkdir(parents=True, exist_ok=True)\n","    path.write_text(json.dumps(obj, indent=2, ensure_ascii=False) + \"\\n\", encoding=\"utf-8\")\n","\n","def append_jsonl(path: Path, record: dict):\n","    path.parent.mkdir(parents=True, exist_ok=True)\n","    with path.open(\"a\", encoding=\"utf-8\") as f:\n","        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n","\n","def get_env_fingerprint(run_dir: Path) -> dict:\n","    freeze_path = run_dir / \"pip_freeze.txt\"\n","    try:\n","        freeze = subprocess.check_output([\"pip\", \"freeze\"], text=True)\n","        freeze_path.write_text(freeze, encoding=\"utf-8\")\n","    except Exception as e:\n","        freeze_path.write_text(f\"pip freeze failed: {e}\\n\", encoding=\"utf-8\")\n","    return {\n","        \"timestamp_utc\": now_iso(),\n","        \"python_version\": platform.python_version(),\n","        \"platform\": platform.platform(),\n","        \"pip_freeze_path\": str(freeze_path),\n","    }\n","\n","BASE_CONFIG = {\n","    \"project\": \"AI_FOR_AUDIT_AND_ACCOUNTING\",\n","    \"chapter\": 1,\n","    \"level\": 1,\n","    \"scope\": \"Chatbots only (single-turn drafting/formatting). No verification. No procedures. No evidence.\",\n","    \"model\": MODEL,\n","    \"params\": {\"temperature\": TEMPERATURE, \"max_tokens\": MAX_TOKENS},\n","    \"controls\": {\n","        \"capability_risk_controls_law\": \"capability↑ ⇒ risk↑ ⇒ controls↑\",\n","        \"data_minimization_default\": True,\n","        \"no_invented_authority\": True,\n","        \"structured_outputs_required\": True,\n","        \"human_review_required\": True,\n","        \"audit_trail_every_run\": True\n","    }\n","}\n","CONFIG_HASH = sha256_text(json.dumps(BASE_CONFIG, sort_keys=True))\n","RUN_ID = f\"{RUN_TS}_{CONFIG_HASH[:10]}\"\n","\n","MANIFEST_PATH = RUN_DIR / \"run_manifest.json\"\n","PROMPTS_LOG_PATH = RUN_DIR / \"prompts_log.jsonl\"\n","RISK_LOG_PATH = RUN_DIR / \"risk_log.json\"\n","\n","env_fp = get_env_fingerprint(RUN_DIR)\n","\n","run_manifest = {\n","    \"run_id\": RUN_ID,\n","    \"timestamp_utc\": now_iso(),\n","    \"author\": \"Alejandro Reynoso, Chief Scientist DEFI CAPITAL RESEARCH; External Lecturer, Judge Business School Cambridge\",\n","    \"base_config\": BASE_CONFIG,\n","    \"config_sha256\": CONFIG_HASH,\n","    \"environment\": env_fp\n","}\n","\n","write_json(MANIFEST_PATH, run_manifest)\n","PROMPTS_LOG_PATH.write_text(\"\", encoding=\"utf-8\")\n","write_json(RISK_LOG_PATH, {\"run_id\": RUN_ID, \"timestamp_utc\": now_iso(), \"entries\": []})\n","\n","print(\"Created:\")\n","print(\" -\", str(MANIFEST_PATH))\n","print(\" -\", str(PROMPTS_LOG_PATH))\n","print(\" -\", str(RISK_LOG_PATH))\n","print(\"Deliverables dir:\", str(DELIVERABLES_DIR))\n","print(\"RUN_ID:\", RUN_ID)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oIl8TpNymK9E","executionInfo":{"status":"ok","timestamp":1768144028001,"user_tz":360,"elapsed":1580,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"deecefec-3b62-409c-b34d-f1cf0985b9d0"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Created:\n"," - /content/ai_audit_ch1_runs/run_20260111T150551Z/run_manifest.json\n"," - /content/ai_audit_ch1_runs/run_20260111T150551Z/prompts_log.jsonl\n"," - /content/ai_audit_ch1_runs/run_20260111T150551Z/risk_log.json\n","Deliverables dir: /content/ai_audit_ch1_runs/run_20260111T150551Z/deliverables\n","RUN_ID: 20260111T150551Z_11fdf22919\n"]}]},{"cell_type":"markdown","source":["##5.PROTECTING CONFIDENTIAL INFORMATION"],"metadata":{"id":"aFfOfCZmMgx4"}},{"cell_type":"markdown","source":["###5.1.OVERVIEW"],"metadata":{"id":"tIlOMU-SMjni"}},{"cell_type":"markdown","source":["**Cell 5: Protecting Confidential Information (Redaction and Data Minimization)**\n","\n","**What This Cell Does**\n","\n","Cell 5 builds a confidentiality protection system that automatically detects and removes sensitive information from text before it gets sent to Claude. Think of it as having a careful assistant who reviews every document you're about to share and blacks out names, addresses, phone numbers, and other identifying details.\n","\n","This cell creates two critical safety functions: one that redacts sensitive data from text, and another that restructures your input into minimal, sanitized facts that are safe to send to an external AI service.\n","\n","**Why Redaction Matters in Professional Services**\n","\n","When you work with client data in accounting or audit, you're bound by confidentiality agreements and professional standards. Sending raw client information to any external service – including AI services – creates several risks:\n","\n","Your client's confidential information might be stored on servers you don't control. Even if the AI provider promises privacy, you're still transmitting sensitive data outside your organization. Most firm policies prohibit sharing client identifiers, account numbers, or personally identifiable information with external vendors without explicit consent.\n","\n","Even for educational or training purposes, using real client data is inappropriate. This cell enforces a \"redact by default\" philosophy, making it harder to accidentally expose confidential information.\n","\n","**The Five Types of Sensitive Data This Cell Detects**\n","\n","**Email addresses:** The cell uses pattern matching to find anything that looks like an email address (something@something.com) and replaces it with [REDACTED_EMAIL]. This prevents identifying individuals or organizations through their email domains.\n","\n","**Phone numbers:** It detects US phone numbers in multiple formats – with or without country codes, with parentheses, dashes, or spaces – and replaces them with [REDACTED_PHONE]. Phone numbers can identify individuals or link back to organizations.\n","\n","**Social Security Numbers:** Any pattern matching XXX-XX-XXXX gets replaced with [REDACTED_SSN]. SSNs are extremely sensitive personally identifiable information that should never be in AI prompts.\n","\n","**Physical addresses:** The system looks for patterns like \"123 Main Street\" and replaces them with [REDACTED_ADDRESS]. Addresses can identify individuals, businesses, or properties being audited.\n","\n","**Names (heuristic):** This is the trickiest one. The cell looks for patterns of capitalized words that might be names (like \"John Smith\") and replaces them with [REDACTED_NAME]. The cell explicitly notes this is \"heuristic\" and \"may over/under redact\" because distinguishing names from other capitalized words is imperfect.\n","\n","**Understanding Pattern Matching and Its Limitations**\n","\n","The redaction system uses \"regular expressions\" – pattern matching rules that describe what sensitive data looks like. For example, an email pattern says \"look for letters and numbers, then an @ symbol, then more letters, then a dot, then 2+ letters.\"\n","\n","**This approach has important limitations you need to understand:**\n","\n","It's not perfect. Creative formats might slip through. Someone writing \"call me at five five five, one two one two\" wouldn't be caught because it doesn't match the phone number pattern.\n","\n","It might over-redact. The name heuristic might flag \"New York\" or \"Main Street\" as names because they're capitalized words in sequence. This is acceptable – better to over-redact than under-redact.\n","\n","It doesn't understand context. If someone writes \"the controller's analysis shows...\" the cell doesn't know \"controller\" might be identifying information in context.\n","\n","New types of sensitive data aren't covered. Client IDs, project codes, proprietary product names, or internal jargon might be identifying but won't match these five patterns.\n","\n","**The Important Disclaimer**\n","\n","The cell explicitly states: \"Redaction is best-effort and imperfect.\" This is crucial honesty. The redaction system provides a safety layer, but it's not foolproof. Users must still exercise professional judgment. The message is: \"Don't rely entirely on automatic redaction – think before you paste.\"\n","\n","**The build_minimum_necessary() Function**\n","\n","This function implements a data minimization principle: only send what's absolutely necessary to accomplish the task.\n","\n","Here's what it does: It takes your input text, runs it through the redaction system, breaks it into separate facts or statements, keeps only the first 15 items, and formats them as bullet points.\n","\n","Why limit to 15 items? This forces you to be concise. Most drafting tasks don't need elaborate context. By capping at 15 facts, the function discourages dumping large blocks of text into prompts. Fewer facts mean less risk, less cost, and more focused outputs.\n","\n","The function returns three things: sanitized_facts (the bullet list ready to send to Claude), removed_fields (a summary of what was redacted), and redacted_text (the full text after redaction, for reference).\n","\n","**The Demo: Seeing Redaction in Action**\n","\n","The cell includes a demonstration using completely fake data: \"ACME Corp CFO John Doe emailed jane.doe@example.com. Call (312) 555-1212. Address 123 Main St. SSN 123-45-6789.\"\n","\n","When you run the cell, you see this transform into: \"ACME Corp CFO [REDACTED_NAME] emailed [REDACTED_EMAIL]. Call [REDACTED_PHONE]. Address [REDACTED_ADDRESS]. SSN [REDACTED_SSN].\"\n","\n","The removed summary shows exactly what was caught: one email, one phone number, one SSN, one address, and two names (the name heuristic caught \"John Doe\").\n","\n","**Why This Demo Uses Fake Data**\n","\n","Notice the demo uses obviously fake information – ACME Corp, generic names, and 555 phone numbers (which are reserved for fiction). This reinforces the pedagogical point: even in demonstrations and testing, we should avoid using real data.\n","\n","**Professional Judgment Still Required**\n","\n","The cell provides tools, not guarantees. Consider this scenario: You're documenting a walkthrough of ACME Corporation's revenue process. You write: \"The controller reviews the reconciliation every Monday morning before the weekly meeting.\"\n","\n","The redaction system sees nothing to redact – no emails, phones, SSNs, addresses, or obvious names. But \"controller\" might be identifying if ACME only has one controller. \"Monday morning\" and \"weekly meeting\" describe internal processes. This information might be confidential depending on your engagement terms.\n","\n","The cell can't make these judgment calls. You must still think about context, relationships, and engagement-specific confidentiality requirements.\n","\n","**The Memory Safety Detail**\n","\n","Notice the cell stores the original user input in a variable called \"_original_in_memory_only\" and explicitly notes this variable is never written to disk. Only the redacted version gets logged to files. This prevents accidentally creating a permanent record of unredacted client data.\n","\n","**Integration with the Governance System**\n","\n","The removed_fields summary that this function generates will be included in the audit trail. Reviewers can see \"this prompt had 2 emails and 3 names redacted\" which provides transparency about what information was sanitized before being sent to the AI.\n","\n","**The Core Message**\n","\n","This cell embodies defensive information security: assume that any data sent to external services could be exposed, therefore minimize and sanitize aggressively. The goal is making it difficult to accidentally breach confidentiality, even if you're working quickly or under pressure.\n","\n","Redaction is your first line of defense, but professional judgment is your final safeguard. Use both."],"metadata":{"id":"ksHvcArXMxMR"}},{"cell_type":"markdown","source":["###5.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"x7z8cMnQMx3g"}},{"cell_type":"code","source":["EMAIL_RE = re.compile(r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b\")\n","PHONE_RE = re.compile(r\"(\\+?1[\\s.-]?)?(\\(?\\d{3}\\)?[\\s.-]?)\\d{3}[\\s.-]?\\d{4}\\b\")\n","SSN_RE = re.compile(r\"\\b\\d{3}-\\d{2}-\\d{4}\\b\")\n","ADDR_RE = re.compile(r\"\\b\\d{1,6}\\s+[A-Za-z0-9.\\-]+\\s+(Street|St|Avenue|Ave|Road|Rd|Boulevard|Blvd|Lane|Ln|Drive|Dr|Court|Ct)\\b\", re.IGNORECASE)\n","NAME_RE = re.compile(r\"\\b([A-Z][a-z]+)\\s+([A-Z][a-z]+)\\b\")\n","\n","def redact(text: str):\n","    removed = []\n","    t = text\n","\n","    def sub_and_record(pattern, label):\n","        nonlocal t, removed\n","        matches = pattern.findall(t)\n","        if matches:\n","            removed.append({\"type\": label, \"count\": len(matches)})\n","            t = pattern.sub(f\"[REDACTED_{label.upper()}]\", t)\n","\n","    sub_and_record(EMAIL_RE, \"email\")\n","    sub_and_record(PHONE_RE, \"phone\")\n","    sub_and_record(SSN_RE, \"ssn\")\n","    sub_and_record(ADDR_RE, \"address\")\n","\n","    nm = NAME_RE.findall(t)\n","    if nm:\n","        removed.append({\"type\": \"name_heuristic\", \"count\": len(nm), \"note\": \"Heuristic; may over/under redact.\"})\n","        t = NAME_RE.sub(\"[REDACTED_NAME]\", t)\n","\n","    return t, removed\n","\n","def build_minimum_necessary(user_text: str):\n","    redacted_text, removed = redact(user_text)\n","    parts = [p.strip() for p in re.split(r\"[.\\n]+\", redacted_text) if p.strip()]\n","    sanitized_facts = [f\"- {p}\" for p in parts[:15]]\n","    return {\"sanitized_facts\": sanitized_facts, \"removed_fields\": removed, \"redacted_text\": redacted_text}\n","\n","demo = \"ACME Corp CFO John Doe emailed jane.doe@example.com. Call (312) 555-1212. Address 123 Main St. SSN 123-45-6789.\"\n","demo_redacted, demo_removed = redact(demo)\n","\n","print(\"DEMO (FAKE) BEFORE:\\n\", demo)\n","print(\"\\nDEMO AFTER:\\n\", demo_redacted)\n","print(\"\\nRemoved summary:\\n\", json.dumps(demo_removed, indent=2))"],"metadata":{"id":"VaSIhXNScYz0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768144032616,"user_tz":360,"elapsed":17,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"5fd0806f-a3c2-400a-fbcc-41825d6de586"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["DEMO (FAKE) BEFORE:\n"," ACME Corp CFO John Doe emailed jane.doe@example.com. Call (312) 555-1212. Address 123 Main St. SSN 123-45-6789.\n","\n","DEMO AFTER:\n"," ACME Corp CFO [REDACTED_NAME] emailed [REDACTED_EMAIL]. Call [REDACTED_PHONE]. Address [REDACTED_ADDRESS]. SSN [REDACTED_SSN].\n","\n","Removed summary:\n"," [\n","  {\n","    \"type\": \"email\",\n","    \"count\": 1\n","  },\n","  {\n","    \"type\": \"phone\",\n","    \"count\": 1\n","  },\n","  {\n","    \"type\": \"ssn\",\n","    \"count\": 1\n","  },\n","  {\n","    \"type\": \"address\",\n","    \"count\": 1\n","  },\n","  {\n","    \"type\": \"name_heuristic\",\n","    \"count\": 1,\n","    \"note\": \"Heuristic; may over/under redact.\"\n","  }\n","]\n"]}]},{"cell_type":"markdown","source":["##6.CLAUDE WRAPPER"],"metadata":{"id":"uVJjvhvVM0E8"}},{"cell_type":"markdown","source":["###6.1.OVERVIEW"],"metadata":{"id":"MyxD2F2XM1J3"}},{"cell_type":"markdown","source":["**Cell 6: The AI Conversation Engine (Strict Controls and Automated Safety Checks)**\n","\n","**What This Cell Does**\n","\n","Cell 6 creates the core function that communicates with Claude AI – but with extensive safety guardrails built in. Think of it as hiring a contractor who not only does the work you request but also documents every step, checks for quality issues, flags potential problems, and refuses to take shortcuts that could cause trouble later.\n","\n","This is the most complex cell in the notebook because it handles the actual interaction with Claude while enforcing strict formatting rules, performing automated risk detection, maintaining audit logs, and ensuring every output meets minimum professional standards.\n","\n","**Understanding the Strict JSON Schema**\n","\n","The cell begins by defining nine required keys that every Claude response must include, in exact order: task, facts_provided, assumptions, open_questions, analysis, risks, draft_output, verification_status, and questions_to_verify.\n","\n","Why such rigid structure? In professional services, consistency matters enormously. Imagine if every staff member formatted workpapers differently – review would be chaos. The strict schema ensures that whether you run this notebook today or six months from now, whether you're drafting a memo or an email, the output structure is identical.\n","\n","**The STRICT_KEYS list defines what information must be present:**\n","\n","The task name reminds you what you asked for. The facts_provided list shows what information Claude received (creating transparency). The assumptions list reveals what Claude guessed or inferred beyond the facts (crucial for identifying potential problems). The open_questions list forces Claude to acknowledge what information is missing (preventing overconfidence). The analysis section explains Claude's drafting choices and limitations. The risks list contains structured risk flags. The draft_output is the actual text you requested. The verification_status must always say \"Not verified\" (reminding everyone this is draft only). The questions_to_verify lists what needs external confirmation.\n","\n","**Why \"Not Verified\" Is Non-Negotiable**\n","\n","Notice that verification_status must always equal \"Not verified\" – this is hardcoded and cannot be changed. This might seem overly cautious, but it's deliberately designed for professional accountability.\n","\n","Claude cannot verify facts. It cannot confirm that an accounting standard citation is correct. It cannot validate that a control description matches reality. It cannot determine if a tax position analysis is accurate. All it can do is draft text based on what you tell it.\n","\n","By forcing every output to say \"Not verified,\" the cell ensures no one can mistake AI drafts for reviewed, approved, or evidence-backed work. This is a bright line rule: AI outputs are always drafts requiring human verification.\n","\n","**The Authority Detection System**\n","\n","The cell includes a pattern that detects authority-like terms: ASC, PCAOB, AICPA, AU-C, GAAS, AS (followed by numbers), and SEC. Why? Because one of the most dangerous AI failure modes is confidently citing nonexistent or incorrect standards.\n","\n","Imagine Claude drafts: \"According to ASC 606 paragraph 15, revenue should be recognized when...\" If that citation is wrong, and someone relies on it without checking, you have a professional liability problem.\n","\n","The authority detection system watches for these terms in outputs. If it finds them, it automatically adds a high-severity hallucination risk flag and reinforces that the content is \"Not verified\" and must be checked externally.\n","\n","This doesn't mean Claude can't mention standards – it means any mention of standards triggers extra scrutiny and documentation.\n","\n","**The Mandatory Disclaimer**\n","\n","Every draft_output must begin with: \"NOT ACCOUNTING/AUDIT/TAX ADVICE. CPA review and engagement sign-off required.\"\n","\n","This disclaimer serves multiple purposes. It protects against misuse by making the output's limitations explicit. It reminds everyone that AI drafts are not substitutes for professional judgment. It documents that outputs require human review before any reliance. It establishes clear expectations about the workflow: AI drafts first, humans review and approve second.\n","\n","**The System Prompt: Instructions to Claude**\n","\n","When you call Claude, you send two things: a system prompt (general instructions about how to behave) and a user prompt (your specific request). The cell builds a detailed system prompt that tells Claude:\n","\n","You are a Level 1 chatbot for US CPAs and auditors – establishing role and context. You ONLY draft and format from provided facts – limiting scope strictly. You do NOT verify facts, perform procedures, or create evidence – preventing overreach. Return STRICT JSON only with exact keys in exact order – enforcing structure. Do NOT invent facts, numbers, evidence, procedures, or conclusions – preventing hallucination. Do NOT fabricate standards citations – addressing the authority problem. Analysis must describe drafting choices only, not technical conclusions – keeping scope limited. Risks must include specific structured objects – ensuring risk documentation. Draft output MUST start with the disclaimer – enforcing the safety message. Tone must be professional, cautious, non-overconfident – setting appropriate voice.\n","\n","These instructions attempt to shape Claude's behavior toward safe, professional outputs. They're not foolproof (Claude is a statistical model, not a rule-following system), which is why validation and automated checks are necessary.\n","\n","**The Validation Function**\n","\n","After Claude responds, the cell validates the output structure. It checks: Is it a dictionary? Does it have exactly the nine required keys in exact order? Is verification_status set to \"Not verified\"? Are facts_provided, assumptions, open_questions, risks, and questions_to_verify all lists? Are analysis and draft_output strings?\n","\n","If any check fails, the response is considered invalid. The cell will retry once with a correction instruction. If it still fails, the cell creates a safe fallback response that says \"Draft unavailable due to JSON parsing failure\" with appropriate risk flags.\n","\n","This validation prevents malformed outputs from entering your workflow. Better to get a clear failure message than a partially-correct response that might be misused.\n","\n","**Automated Risk Detection**\n","\n","Even after Claude responds and the structure validates, the cell performs automated risk checks:\n","\n","**Missing open_questions check:** If the open_questions list is empty, that's suspicious. Almost every real-world drafting task has some missing information or ambiguity. An empty list suggests Claude is being overconfident. The cell adds a medium-severity risk flag noting this problem.\n","\n","**Authority citation check:** If the draft_output contains any authority-like terms (ASC, PCAOB, etc.), the cell adds a high-severity hallucination risk flag. This doesn't mean the citation is wrong – it means it requires careful verification because AI-generated citations are high-risk.\n","\n","These automated checks catch common problems without human intervention, creating a first-pass quality screen.\n","\n","**The Logging System**\n","\n","Every interaction with Claude generates two types of logs:\n","\n","**Prompt log entry:** Records the run ID, timestamp, model and parameters used, task name, hash of the prompt, hash of the response, the redacted prompt text, and the full parsed response. This creates a complete record of what was asked and what was answered.\n","\n","**Risk log entry:** Records the timestamp, task, prompt and response hashes (linking to the prompt log), all risk flags from this interaction, and the verification status. This aggregates risk information across the session.\n","\n","The use of hashes (unique fingerprints) is crucial. If someone questions whether an output has been altered, you can recalculate the hash and compare. If the hashes match, the content is unchanged. If they don't match, the content was edited.\n","\n","**Understanding the Smoke Test**\n","\n","The cell ends with a smoke test – a simple trial to verify everything works. It asks Claude to draft a short internal email using three synthetic facts. The test checks that the response has the correct verification_status and all nine required keys.\n","\n","This smoke test serves multiple purposes: It confirms your API connection works. It validates that the strict JSON parsing succeeds. It shows you an example of what outputs look like. It gives you immediate feedback if something is misconfigured.\n","\n","If the smoke test fails, you know there's a problem before you start substantive work.\n","\n","**The Retry Logic**\n","\n","Notice the cell includes retry logic – if Claude's first response doesn't validate, the cell automatically tries again with a correction instruction. This handles transient failures (like Claude occasionally forgetting to include a key) without requiring manual intervention.\n","\n","After one retry, if validation still fails, the cell creates the safe fallback response. This prevents infinite loops while maximizing the chance of getting a valid output.\n","\n","**Why This Level of Control Is Necessary**\n","\n","You might wonder: why so many rules, checks, and validations? Can't we just trust Claude to respond appropriately?\n","\n","The answer is no – not for professional work. AI models are probabilistic. They sometimes forget instructions, occasionally hallucinate facts, might format inconsistently, and can be overconfident. In creative writing, these quirks are acceptable. In professional services, they create liability.\n","\n","The extensive controls in this cell transform Claude from an unpredictable creative tool into a reliable drafting assistant with documented limitations and automated safety checks.\n","\n","**Integration with Professional Standards**\n","\n","This cell operationalizes several professional principles: Competence requires understanding tool limitations (hence the strict scope and \"Not verified\" rule). Due care requires adequate supervision (hence the human review requirements). Documentation standards require maintaining sufficient records (hence the comprehensive logging). Risk management requires identifying and addressing risks (hence the automated risk detection).\n","\n","The cell doesn't just enable AI use – it enables responsible AI use that could withstand professional scrutiny.\n","\n","**What Success Looks Like**\n","\n","When this cell runs successfully, you see three confirmations: \"Chatbot wrapper ready (Level 1 only)\" confirming the function is defined. \"Smoke test OK. verification_status: Not verified\" confirming a test interaction worked. \"Keys: [list of nine keys]\" confirming the structure is correct.\n","\n","These confirmations tell you the AI conversation engine is operational, configured correctly, and ready for professional drafting tasks – with all safety systems active."],"metadata":{"id":"NbI8D2MMNp2V"}},{"cell_type":"markdown","source":["###6.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"HYi01MJHM25b"}},{"cell_type":"code","source":["STRICT_KEYS = [\n","    \"task\",\n","    \"facts_provided\",\n","    \"assumptions\",\n","    \"open_questions\",\n","    \"analysis\",\n","    \"risks\",\n","    \"draft_output\",\n","    \"verification_status\",\n","    \"questions_to_verify\"\n","]\n","\n","AUTH_LIKE_RE = re.compile(r\"\\b(ASC|PCAOB|AICPA|AU-C|GAAS|AS\\s*\\d+|SEC)\\b\", re.IGNORECASE)\n","\n","DISCLAIMER_LINE = \"NOT ACCOUNTING/AUDIT/TAX ADVICE. CPA review and engagement sign-off required.\"\n","\n","def _validate_schema(obj: dict) -> bool:\n","    if not isinstance(obj, dict): return False\n","    if list(obj.keys()) != STRICT_KEYS: return False\n","    if obj.get(\"verification_status\") != \"Not verified\": return False\n","    if not isinstance(obj[\"facts_provided\"], list): return False\n","    if not isinstance(obj[\"assumptions\"], list): return False\n","    if not isinstance(obj[\"open_questions\"], list): return False\n","    if not isinstance(obj[\"analysis\"], str): return False\n","    if not isinstance(obj[\"risks\"], list): return False\n","    if not isinstance(obj[\"draft_output\"], str): return False\n","    if not isinstance(obj[\"questions_to_verify\"], list): return False\n","    return True\n","\n","def _load_risk_log():\n","    return json.loads(RISK_LOG_PATH.read_text(encoding=\"utf-8\"))\n","\n","def _save_risk_log(obj):\n","    write_json(RISK_LOG_PATH, obj)\n","\n","def call_chatbot(task_name: str, user_prompt: str, facts_bullets: list):\n","    facts_text = \"\\n\".join(facts_bullets)\n","\n","    system = (\n","        \"You are a Level 1 chatbot for US CPAs/auditors.\\n\"\n","        \"You ONLY draft and format text from provided facts. You do NOT verify facts, perform procedures, or create evidence.\\n\"\n","        \"Return STRICT JSON only (no markdown, no extra text), with EXACT keys in EXACT order:\\n\"\n","        + json.dumps(STRICT_KEYS) + \"\\n\"\n","        \"Rules:\\n\"\n","        \"1) Do NOT invent facts, numbers, evidence, procedures performed, or conclusions beyond the facts.\\n\"\n","        \"2) Do NOT fabricate standards/citations (ASC/PCAOB/AICPA/etc.). If standards are relevant, keep Not verified and add questions_to_verify.\\n\"\n","        \"3) analysis must describe drafting choices + missing inputs (not technical conclusions).\\n\"\n","        \"4) risks must include objects: {\\\"type\\\":\\\"confidentiality|independence|hallucination|missing_facts|qc|other\\\", \"\n","        \"\\\"severity\\\":\\\"low|medium|high\\\", \\\"note\\\":\\\"...\\\"}.\\n\"\n","        f\"5) draft_output MUST start with: \\\"{DISCLAIMER_LINE}\\\".\\n\"\n","        \"6) Tone: professional, cautious, non-overconfident.\\n\"\n","    )\n","\n","    user = (\n","        f\"TASK: {task_name}\\n\\n\"\n","        \"FACTS (redacted/synthetic; incomplete by design):\\n\"\n","        f\"{facts_text}\\n\\n\"\n","        \"INSTRUCTIONS:\\n\"\n","        f\"{user_prompt}\\n\\n\"\n","        \"OUTPUT:\\n\"\n","        \"Return JSON only with required keys and ordering.\"\n","    )\n","\n","    prompt_hash = sha256_text(system + \"\\n\" + user)\n","\n","    def _send(u: str):\n","        msg = client.messages.create(\n","            model=MODEL,\n","            max_tokens=MAX_TOKENS,\n","            temperature=TEMPERATURE,\n","            system=system,\n","            messages=[{\"role\": \"user\", \"content\": u}],\n","        )\n","        txt = \"\"\n","        for block in msg.content:\n","            if getattr(block, \"type\", None) == \"text\":\n","                txt += block.text\n","        return txt.strip()\n","\n","    raw = _send(user)\n","\n","    parsed = None\n","    try:\n","        parsed = json.loads(raw)\n","    except Exception:\n","        parsed = None\n","\n","    if parsed is None or not _validate_schema(parsed):\n","        raw2 = _send(user + \"\\n\\nFix output: JSON ONLY, exact keys/order, verification_status must be Not verified.\")\n","        try:\n","            parsed = json.loads(raw2)\n","        except Exception:\n","            parsed = None\n","\n","    if parsed is None or not _validate_schema(parsed):\n","        parsed = {\n","            \"task\": task_name,\n","            \"facts_provided\": facts_bullets,\n","            \"assumptions\": [],\n","            \"open_questions\": [\"Model output failed strict JSON parsing; simplify prompt and rerun.\"],\n","            \"analysis\": \"Draft unavailable due to JSON parsing failure. No verification performed.\",\n","            \"risks\": [{\"type\": \"hallucination\", \"severity\": \"high\", \"note\": \"Invalid JSON output; treat as unreliable.\"}],\n","            \"draft_output\": f\"{DISCLAIMER_LINE}\\n\\n[Draft unavailable due to parsing failure.]\",\n","            \"verification_status\": \"Not verified\",\n","            \"questions_to_verify\": [\"Why did parsing fail? Reduce prompt complexity and rerun.\"]\n","        }\n","\n","    auto_risks = []\n","    if not parsed.get(\"open_questions\"):\n","        auto_risks.append({\"type\": \"missing_facts\", \"severity\": \"medium\", \"note\": \"open_questions is empty; prompts should force missing-info questions.\"})\n","    if AUTH_LIKE_RE.search(parsed.get(\"draft_output\", \"\")):\n","        auto_risks.append({\"type\": \"hallucination\", \"severity\": \"high\", \"note\": \"Draft contains authority-like terms; must remain Not verified and be verified externally.\"})\n","\n","    if auto_risks:\n","        parsed[\"risks\"] = parsed[\"risks\"] + auto_risks\n","        parsed[\"verification_status\"] = \"Not verified\"\n","\n","    response_hash = sha256_text(json.dumps(parsed, ensure_ascii=False))\n","\n","    append_jsonl(PROMPTS_LOG_PATH, {\n","        \"run_id\": RUN_ID,\n","        \"timestamp_utc\": now_iso(),\n","        \"model\": MODEL,\n","        \"params\": {\"temperature\": TEMPERATURE, \"max_tokens\": MAX_TOKENS},\n","        \"task\": task_name,\n","        \"prompt_hash\": prompt_hash,\n","        \"response_hash\": response_hash,\n","        \"prompt_redacted\": user,\n","        \"response_redacted\": parsed\n","    })\n","\n","    risk_log = _load_risk_log()\n","    risk_log[\"entries\"].append({\n","        \"timestamp_utc\": now_iso(),\n","        \"task\": task_name,\n","        \"prompt_hash\": prompt_hash,\n","        \"response_hash\": response_hash,\n","        \"risks\": parsed.get(\"risks\", []),\n","        \"verification_status\": \"Not verified\"\n","    })\n","    _save_risk_log(risk_log)\n","\n","    return parsed\n","\n","print(\"Chatbot wrapper ready (Level 1 only).\")\n","\n","smoke = call_chatbot(\n","    \"SMOKE_TEST: Internal email draft\",\n","    \"Draft a short internal email to the audit manager summarizing status. Facts only. No standards.\",\n","    [\"- Testing is in progress (synthetic).\", \"- Two follow-ups are pending (synthetic).\", \"- No client identifiers included.\"]\n",")\n","print(\"Smoke test OK. verification_status:\", smoke[\"verification_status\"])\n","print(\"Keys:\", list(smoke.keys()))"],"metadata":{"id":"8fY9udIwcaKS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768144066184,"user_tz":360,"elapsed":29463,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"637f2a25-6635-487a-9a56-c983681ea00c"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Chatbot wrapper ready (Level 1 only).\n","Smoke test OK. verification_status: Not verified\n","Keys: ['task', 'facts_provided', 'assumptions', 'open_questions', 'analysis', 'risks', 'draft_output', 'verification_status', 'questions_to_verify']\n"]}]},{"cell_type":"markdown","source":["##7.MINI CASE BUILDER"],"metadata":{"id":"Dr34h4v4M8SU"}},{"cell_type":"markdown","source":["##7.1.OVERVIEW"],"metadata":{"id":"EnAuC2ckM_GU"}},{"cell_type":"markdown","source":["**Cell 7: Building Real-World Practice Scenarios (The Four Mini-Cases)**\n","\n","**What This Cell Does**\n","\n","Cell 7 creates four realistic practice scenarios that mirror actual tasks accounting and audit professionals face daily. Think of this as a case study library – each scenario is carefully designed to teach you how to use AI safely for specific types of professional work while highlighting the boundaries of what AI can and cannot do.\n","\n","These aren't generic examples. Each case is deliberately aligned with a major practice area: financial statement audits, internal controls and SOX compliance, tax and complex accounting, and training and methodology development. Together, they cover the breadth of situations where Level 1 AI drafting can add value.\n","\n","**Why Case-Based Learning Matters**\n","\n","Professional education works best through examples. You could read abstract principles about AI limitations all day, but seeing \"here's a revenue testing workpaper scenario, here's what's appropriate to ask AI to draft, and here's what you must still do yourself\" makes the concepts concrete and actionable.\n","\n","Each case includes three components: a task description explaining what you're trying to accomplish, a facts list providing the raw information available (deliberately incomplete), and a prompt giving specific instructions to Claude about what to draft and what boundaries to respect.\n","\n","**Case 1: Financial Statement Audit Workpaper**\n","\n","This scenario focuses on documenting a substantive analytical procedure over revenue – one of the most common audit procedures.\n","\n","The facts provided are intentionally sparse: you're documenting an analytical procedure, you have an expectation about revenue trends, you observed a material increase in one segment, management gave you an explanation about mix shift and contract timing, and evidence references are not included.\n","\n","Notice what's missing: specific numbers, detailed evidence, complete explanations, testing results, and conclusions. This mirrors reality – when you start drafting a workpaper, you often have high-level observations but incomplete documentation.\n","\n","The prompt asks Claude to draft a narrative with standard workpaper headings: Purpose, Procedure, Results, Conclusion. But it explicitly prohibits inventing procedures performed or evidence obtained. Where support is missing, Claude must flag it in open_questions and questions_to_verify.\n","\n","This case teaches a critical lesson: AI can help structure and format your workpaper narrative, but it cannot and should not fabricate the substance. The procedure performed, evidence obtained, and conclusion reached must come from actual audit work, not AI generation.\n","\n","**Why This Matters:** A common temptation is asking AI to \"complete\" incomplete workpapers by filling in missing details. This case demonstrates the proper boundary – AI formats and organizes what you know, but flags what you don't know, rather than inventing content.\n","\n","**Case 2: SOX/ICFR Walkthrough and Documentation**\n","\n","This scenario addresses internal controls over financial reporting, specifically documenting a walkthrough of the order-to-cash process and requesting additional support.\n","\n","The facts describe walkthrough notes at a high level: manual review of revenue entries, some IT dependency involving a system report, and incomplete details about the control design. The task is to draft both a control narrative and a PBC (Provided By Client) request email.\n","\n","The prompt has specific prohibitions: don't cite SOX requirements or standards as facts, don't state that testing was performed, and keep analysis limited to drafting choices. Both deliverables should appear in the draft_output with clear labels.\n","\n","This case teaches several lessons simultaneously. First, control documentation requires specific elements (who, what, when, control objective, IT dependencies) but must be based on actual observations, not assumptions. Second, requesting client support via email is a routine task where AI can help with professional tone and structure, but you must think about what to request. Third, documentation and communication often go together – you need both the formal narrative and the informal request.\n","\n","**Why This Matters:** SOX compliance generates massive documentation requirements. AI can accelerate the drafting of control descriptions and routine communications, but cannot substitute for understanding the control environment or designing test procedures. This case shows where the efficiency gains are – and where human judgment remains essential.\n","\n","**Case 3: Tax and ASC 740 Documentation**\n","\n","This scenario tackles one of the most technically complex areas: uncertain tax positions and income tax accounting under ASC 740.\n","\n","The facts establish that you need to document an uncertain tax position related to a cross-border services arrangement, but facts are incomplete and no authoritative sources are provided. The task is to create both an internal memo shell (with appropriate headings and placeholders) and a document request list for the provision binder.\n","\n","The prompt explicitly warns: don't cite ASC or tax authorities unless provided, don't reach a technical conclusion, and use open_questions and questions_to_verify for anything requiring expertise or research.\n","\n","This case is particularly important because tax and technical accounting are areas where AI hallucination risks are highest. Tax law is complex, jurisdiction-specific, and frequently updated. Accounting standards like ASC 740 involve detailed technical requirements. AI models trained on general internet content may have outdated, incomplete, or incorrect information about these specialized areas.\n","\n","**Why This Matters:** The case demonstrates that AI can help you structure your thinking (create a memo template, organize a request list) but absolutely cannot provide technical tax or accounting analysis. The memo shell will have sections like \"Facts,\" \"Issues,\" \"Analysis,\" and \"Conclusion\" – but filling those sections with correct technical content requires human expertise, current research, and careful judgment.\n","\n","**Case 4: Training and Methodology Development**\n","\n","This scenario shifts from client work to internal firm activities: creating training materials for staff about how to use AI safely.\n","\n","The facts specify that you're developing training for new audit staff, teaching safe Level 1 drafting workflows and failure modes, emphasizing confidentiality, independence, quality control, and audit trails, and including both a template prompt and a reviewer checklist.\n","\n","The prompt asks for a one-page training handout covering safe uses, unsafe uses, a template prompt, and a reviewer checklist. No standards citations are allowed, and analysis should focus on drafting choices rather than substantive conclusions.\n","\n","This meta-case teaches you about AI by having AI help you teach others about AI. It demonstrates that AI can assist with educational content development – creating structured learning materials, organizing concepts clearly, and drafting reviewer checklists.\n","\n","**Why This Matters:** Firms need to train staff on AI tools quickly and consistently. Using AI to draft training materials (which are then reviewed and refined by experienced staff) accelerates the training development process while ensuring consistency. This case also models the recursive nature of AI use – you can use AI to help teach responsible AI use.\n","\n","**The Deliberate Incompleteness**\n","\n","Notice that every case includes the marker \"(synthetic)\" or \"(incomplete)\" throughout the facts. This is pedagogically intentional – it constantly reminds you that these are teaching scenarios, not real client situations, and that the information provided is purposely incomplete.\n","\n","Real professional work always involves incomplete information at some stage. You start with fragments, gather more details, fill gaps, and eventually reach conclusions. These cases mirror that reality. They don't give you everything you need – they give you enough to start drafting, with clear indicators of what's missing.\n","\n","**The Consistency Across Cases**\n","\n","All four cases share common instructions: don't invent facts, don't cite authorities unless provided, keep analysis limited to drafting choices rather than technical conclusions, and return strict JSON only. This consistency reinforces the boundaries of Level 1 AI use across different practice areas.\n","\n","Whether you're drafting a workpaper, a control narrative, a tax memo, or a training handout, the same principles apply: AI helps with structure and language, humans provide substance and judgment.\n","\n","**The Educational Progression**\n","\n","The cases are ordered intentionally. Case 1 (audit workpaper) is straightforward – documenting what you observed. Case 2 (SOX walkthrough) adds complexity – both documentation and communication. Case 3 (tax memo) introduces high technical risk – an area where AI is particularly dangerous without human oversight. Case 4 (training) is meta-cognitive – using AI to teach about AI.\n","\n","This progression moves from concrete to abstract, from lower-risk to higher-risk, and from task execution to process thinking.\n","\n","**Loading and Confirmation**\n","\n","The cell stores all four case functions in a list called CASES, then loops through them to print each task name. This gives you immediate confirmation that all scenarios are loaded and ready to run.\n","\n","When you execute this cell, you should see four task names printed: the audit workpaper case, the SOX/ICFR case, the tax/ASC 740 case, and the teaching case. This confirmation tells you the practice scenarios are ready for the next cell to execute.\n","\n","**Why Four Cases (Not More, Not Fewer)**\n","\n","Four cases provide enough variety to demonstrate breadth without overwhelming you. Each represents a distinct practice area with different risk profiles and different appropriate uses of AI. Four is also manageable within a single notebook session – you can run all four and compare results within a reasonable timeframe.\n","\n","More cases would dilute focus and increase runtime. Fewer cases would fail to demonstrate the range of applications. Four strikes the pedagogical balance between comprehensiveness and practicality.\n","\n","**The Foundation for Practice**\n","\n","These cases aren't just demonstrations – they're templates. When you face similar real-world situations, you can adapt these case structures: take the fact pattern format, modify it for your situation (with appropriate redactions), adjust the prompt instructions for your specific needs, and use the same strict JSON output structure for consistency.\n","\n","The cases provide a reusable framework for professional AI-assisted drafting across multiple practice areas, all while maintaining consistent governance and documentation standards."],"metadata":{"id":"EKvlFydjNrmX"}},{"cell_type":"markdown","source":["###7.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"X1KSLRldNBYW"}},{"cell_type":"code","source":["def case_1_fs_audit_workpaper():\n","    task = \"Case 1 — FS Audit: Draft substantive analytics workpaper narrative\"\n","    facts = [\n","        \"- Objective: document a substantive analytical procedure over revenue (synthetic).\",\n","        \"- Expectation: revenue trend should align with volume and pricing (synthetic).\",\n","        \"- Observed: revenue increased materially YoY in one segment (synthetic).\",\n","        \"- Management explanation: mix shift and contract timing (synthetic; incomplete).\",\n","        \"- Evidence references are not included here (synthetic).\"\n","    ]\n","    prompt = (\n","        \"Draft a workpaper narrative with headings: Purpose, Procedure, Results, Conclusion.\\n\"\n","        \"Do NOT invent procedures performed or evidence obtained.\\n\"\n","        \"Where support is missing, put it in open_questions and questions_to_verify.\\n\"\n","        \"Keep analysis limited to drafting choices + missing inputs (no technical conclusions).\\n\"\n","        \"Return strict JSON only.\"\n","    )\n","    return task, facts, prompt\n","\n","def case_2_sox_icfr_walkthrough():\n","    task = \"Case 2 — SOX/ICFR: Draft walkthrough/control narrative + draft PBC request email\"\n","    facts = [\n","        \"- Process: order-to-cash walkthrough notes summarized (synthetic).\",\n","        \"- Control: manual review of revenue entries described at high level (synthetic; incomplete).\",\n","        \"- IT dependency: a system report is used; details unknown (synthetic).\",\n","        \"- Goal: draft narrative + a draft PBC email requesting support (synthetic).\"\n","    ]\n","    prompt = (\n","        \"Create (1) a control narrative (who/what/when/control objective/IT dependency) and (2) a draft PBC request email.\\n\"\n","        \"Do NOT cite SOX requirements or standards as facts.\\n\"\n","        \"Do NOT state testing was performed.\\n\"\n","        \"Keep analysis limited to drafting choices + missing inputs.\\n\"\n","        \"Return strict JSON only; put both drafted items inside draft_output with clear labels.\"\n","    )\n","    return task, facts, prompt\n","\n","def case_3_tax_asc740_drafting():\n","    task = \"Case 3 — Tax/ASC 740: Draft UTP memo shell + provision binder request list\"\n","    facts = [\n","        \"- Issue: uncertain tax position documentation is needed (synthetic).\",\n","        \"- Facts: cross-border services arrangement; incomplete facts available (synthetic).\",\n","        \"- No authorities provided; keep anything authority-like Not verified (synthetic).\",\n","        \"- Goal: memo shell + request list (synthetic).\"\n","    ]\n","    prompt = (\n","        \"Draft (1) an internal memo shell with headings and placeholders, and (2) a provision binder/document request list.\\n\"\n","        \"Do NOT cite ASC or tax authorities unless provided.\\n\"\n","        \"Do NOT reach a technical conclusion; use open_questions and questions_to_verify.\\n\"\n","        \"Keep analysis limited to drafting choices + missing inputs.\\n\"\n","        \"Return strict JSON only; include both drafted items inside draft_output with clear labels.\"\n","    )\n","    return task, facts, prompt\n","\n","def case_4_teaching_handout():\n","    task = \"Case 4 — Teaching/Methodology: Draft staff training handout for Level 1 chatbots\"\n","    facts = [\n","        \"- Audience: new audit staff (synthetic).\",\n","        \"- Goal: teach safe Level 1 drafting workflows and failure modes (synthetic).\",\n","        \"- Must emphasize confidentiality, independence, QC, and audit trail artifacts (synthetic).\",\n","        \"- Must include a template prompt + reviewer checklist (synthetic).\"\n","    ]\n","    prompt = (\n","        \"Draft a one-page training handout with: safe uses, unsafe uses, a template prompt, and a reviewer checklist.\\n\"\n","        \"No standards citations.\\n\"\n","        \"Keep analysis limited to drafting choices + missing inputs.\\n\"\n","        \"Return strict JSON only.\"\n","    )\n","    return task, facts, prompt\n","\n","CASES = [\n","    case_1_fs_audit_workpaper,\n","    case_2_sox_icfr_walkthrough,\n","    case_3_tax_asc740_drafting,\n","    case_4_teaching_handout\n","]\n","\n","for fn in CASES:\n","    t, _, _ = fn()\n","    print(\"Loaded:\", t)"],"metadata":{"id":"pNWHyi2bcyjn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768144161201,"user_tz":360,"elapsed":38,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"95fffd96-07b8-49f9-ad17-e96fe61b2c6f"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded: Case 1 — FS Audit: Draft substantive analytics workpaper narrative\n","Loaded: Case 2 — SOX/ICFR: Draft walkthrough/control narrative + draft PBC request email\n","Loaded: Case 3 — Tax/ASC 740: Draft UTP memo shell + provision binder request list\n","Loaded: Case 4 — Teaching/Methodology: Draft staff training handout for Level 1 chatbots\n"]}]},{"cell_type":"markdown","source":["##8.EXECUTION"],"metadata":{"id":"E9DiNZg2NOyv"}},{"cell_type":"markdown","source":["###8.1.OVERVIEW"],"metadata":{"id":"Ee1sdukLNP3S"}},{"cell_type":"markdown","source":["**Cell 8: Running the Cases and Creating Deliverables (Execution and Quality Summary)**\n","\n","**What This Cell Does**\n","\n","Cell 8 is where the notebook shifts from setup to execution. It takes the four practice scenarios you loaded in Cell 7, runs each one through the AI conversation engine you built in Cell 6, saves the results in multiple formats for different uses, creates a minimum standards document, and presents you with a plain-text quality summary showing key metrics for each case.\n","\n","Think of this as the production phase – you've built all your tools and prepared your scenarios, now you're actually doing the work and documenting the results professionally.\n","\n","**The Helper Functions: Making Outputs Usable**\n","\n","The cell begins by creating two utility functions that transform raw AI outputs into human-friendly formats.\n","\n","**highest_sev()** analyzes a list of risk flags and determines which has the highest severity level. Risks are categorized as low, medium, or high. This function looks through all the risks flagged for a particular output and tells you the worst one. If there are no risks (unlikely but possible), it defaults to low. This matters because you need to quickly assess which outputs require the most careful review.\n","\n","**render_txt()** converts the structured JSON output from Claude into a readable text document. Remember that Claude returns data in a strict nine-key format optimized for computer processing. While that's great for logging and analysis, it's not friendly for human review. This function takes that structured data and creates a formatted text file with clear headings, bullet points, and sections that a human reviewer can easily read and annotate.\n","\n","The rendered text includes the mandatory disclaimer at the top, then presents each section clearly: the task name, facts provided, assumptions made, open questions identified, analysis notes, risk flags with severity levels, the actual draft output, verification status, and questions requiring external verification.\n","\n","**The Minimum Standard Document**\n","\n","Before running any cases, the cell creates a critical reference document called \"level1_minimum_standard.txt\" and saves it in the deliverables folder.\n","\n","This document establishes the professional baseline for safe Level 1 AI use in audit and accounting contexts. It's not just educational – it's a compliance reference that should be consulted when determining whether a particular AI use case is appropriate.\n","\n","**The seven minimum standards are:**\n","\n","Use firm-approved tools and configurations, and comply with firm AI policy. This acknowledges that individual judgment must align with organizational policy. What's appropriate at one firm may not be at another.\n","\n","Minimize and redact inputs by default. Do not paste confidential client data into prompts. This operationalizes the confidentiality protection principles from Cell 5.\n","\n","Chatbot output is draft language only. It is not audit evidence and does not perform procedures. This draws a bright line – AI outputs cannot substitute for actual audit work.\n","\n","Require structured output with facts provided, assumptions, open questions, risks, and \"Not verified\" status. This enforces the strict JSON schema from Cell 6.\n","\n","Verify any authority-like statement outside the model workflow. This addresses the hallucination risk with standards citations.\n","\n","Maintain audit trail when AI use is material. This requires redacted prompts, outputs, hashes, and reviewer notes – exactly what this notebook creates automatically.\n","\n","Human reviewer sign-off required before client-facing or reliance-bearing use. This ensures no AI output bypasses human judgment.\n","\n","These standards are deliberately conservative. They represent a floor, not a ceiling. Firms can add more restrictions but shouldn't go below these minimums for professional work.\n","\n","**The Execution Loop: Running All Four Cases**\n","\n","The cell now loops through the four cases, executing each one and saving results. For each case, it retrieves the task description, facts list, and prompt instructions, then calls the chatbot function you built in Cell 6.\n","\n","**What happens during each case execution:**\n","\n","Claude receives the task, facts, and instructions. Claude drafts a response attempting to meet all requirements. The response is validated against the strict JSON schema. Automated risk checks run on the output. The prompt and response are logged with hashes. Risk flags are recorded in the risk log. The output is validated for completeness and consistency.\n","\n","After Claude responds, the cell creates two files for each case. A JSON file preserves the complete structured output in machine-readable format. A TXT file presents the same information in human-readable format using the render_txt function.\n","\n","**The file naming convention** is important. The cell takes the task name (like \"Case 1 — FS Audit: Draft substantive analytics workpaper narrative\"), removes special characters, converts to lowercase, and creates a clean filename (like \"case_1_fs_audit_draft_substantive_analytics_workpaper_narrative_output.json\"). This ensures files are consistently named, easy to sort, and compatible with all operating systems.\n","\n","**Why Two Formats Matter**\n","\n","Saving both JSON and TXT versions serves different purposes. The JSON file is authoritative – it contains the exact structured output from Claude with no formatting interpretation. If there's any question about what Claude actually said, you consult the JSON. It's also machine-readable, so you could write scripts to analyze multiple outputs, extract specific fields, or aggregate data across cases.\n","\n","The TXT file is practical – it's what a human reviewer actually reads. You can open it in any text editor, print it, annotate it with comments, or attach it to an email. The TXT file is derived from the JSON, but formatted for human consumption.\n","\n","Professional practice requires both: an authoritative source record (JSON) and a usable working document (TXT).\n","\n","**Building the Summary Table**\n","\n","As each case completes, the cell captures three key metrics: the task name (so you know which case this is), the number of open questions Claude identified (indicating how much information was missing or ambiguous), and the highest risk severity level (indicating which outputs need the most careful review).\n","\n","These metrics are stored in a list called \"rows\" that will be used to create a summary table.\n","\n","**Understanding the Quality Metrics**\n","\n","**Number of open questions** is a transparency indicator. More open questions suggest Claude recognized substantial ambiguity or missing information. This is actually a good sign – it means the AI is being appropriately cautious and flagging gaps rather than filling them with guesses. A case with zero open questions should raise suspicion – does the AI really have everything it needs, or is it being overconfident?\n","\n","**Highest risk severity** is a triage indicator. Cases flagged with high-severity risks need immediate careful review before any use. Medium-severity risks require standard review procedures. Low-severity risks suggest the output is relatively safe but still requires the mandatory human review.\n","\n","These metrics don't tell you whether the output is good or bad – they tell you how carefully you need to review it and what to look for during review.\n","\n","**The Plain-Text Summary Table**\n","\n","After all four cases complete, the cell prints a formatted summary table. The table has three columns: CASE (the task name, truncated to 68 characters if necessary), #OPEN_Q (the number of open questions), and HIGHEST_RISK (the severity level).\n","\n","The table uses simple text formatting with dashes to create borders and column alignment. This old-fashioned approach (rather than a fancy graphical table) is deliberate – it ensures the summary displays correctly in any terminal, notebook viewer, or text file. Accessibility and reliability trump visual sophistication.\n","\n","**What the summary tells you at a glance:** Which cases generated the most questions (indicating higher complexity or less complete facts). Which cases have high-risk flags (requiring priority review attention). Whether the outputs are relatively consistent (similar metrics) or highly variable (very different metrics).\n","\n","For example, you might see that the tax case has more open questions and higher risk than the audit workpaper case. This makes sense – tax matters are more complex, more dependent on specific facts, and higher-risk for AI hallucination. The summary confirms what you'd expect from the case designs.\n","\n","**The Deliverables Confirmation**\n","\n","The cell ends by printing the path to the deliverables directory, confirming where all outputs were saved. This is important because you now have a folder containing nine files: four JSON outputs, four TXT renderings, and the minimum standards document.\n","\n","This folder represents a complete package of AI-generated drafts with full governance documentation. You could zip this folder and send it to a reviewer, archive it for quality control, or reference it in workpapers.\n","\n","**Why This Summary Matters for Learning**\n","\n","The summary table serves a pedagogical purpose beyond just reporting results. By seeing all four cases side-by-side with their metrics, you start to develop intuition about AI behavior patterns.\n","\n","You learn that certain types of tasks consistently generate more questions (complex, technical, fact-dependent tasks). You recognize that certain practice areas have inherently higher risk profiles (tax and technical accounting versus straightforward documentation). You see that AI tools provide transparency about their limitations when properly configured.\n","\n","This meta-learning – learning about the tool's behavior patterns across different scenarios – is as valuable as the specific outputs themselves.\n","\n","**The Professional Documentation Standard**\n","\n","Notice that every output includes the mandatory disclaimer, structured sections, risk flags, and verification status. Even in an educational notebook, the outputs meet professional documentation standards. This isn't accidental – it models what responsible AI use looks like in practice.\n","\n","If you were to take these outputs and show them to a partner or quality control reviewer, they would see: clear task identification, transparent fact basis, acknowledged assumptions, identified gaps, risk documentation, draft content, and clear \"not verified\" status.\n","\n","A reviewer might disagree with specific drafting choices or identify additional risks, but they couldn't complain about lack of documentation or unclear boundaries between AI contribution and human judgment.\n","\n","**Transition to User Practice**\n","\n","With the four mini-cases complete and documented, the notebook has demonstrated the full workflow on pre-designed scenarios. The next step (Cell 9) will let you practice with your own scenarios, using the same tools and producing the same quality of documentation.\n","\n","Cell 8 completes the demonstration phase – you've seen the system work on four realistic cases spanning different practice areas, you have both JSON and TXT outputs, you have a quality summary showing key metrics, and you have a minimum standards document defining the boundaries of safe use.\n","\n","Everything is documented, traceable, and ready for review. This is what professional-grade AI-assisted drafting looks like."],"metadata":{"id":"UPGXnne7NtGW"}},{"cell_type":"markdown","source":["###8.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"BIE5Ni_wNRvq"}},{"cell_type":"code","source":["def highest_sev(risks):\n","    order = {\"low\": 1, \"medium\": 2, \"high\": 3}\n","    if not risks: return \"low\"\n","    mx = max(risks, key=lambda r: order.get(r.get(\"severity\", \"low\"), 1))\n","    return mx.get(\"severity\", \"low\")\n","\n","def render_txt(task: str, obj: dict) -> str:\n","    lines = []\n","    lines.append(DISCLAIMER_LINE)\n","    lines.append(\"\")\n","    lines.append(f\"Task: {task}\")\n","    lines.append(\"\")\n","    lines.append(\"FACTS PROVIDED:\")\n","    for x in obj[\"facts_provided\"]:\n","        lines.append(f\"- {x}\")\n","    lines.append(\"\")\n","    lines.append(\"ASSUMPTIONS:\")\n","    for x in obj[\"assumptions\"]:\n","        lines.append(f\"- {x}\")\n","    lines.append(\"\")\n","    lines.append(\"OPEN QUESTIONS:\")\n","    for x in obj[\"open_questions\"]:\n","        lines.append(f\"- {x}\")\n","    lines.append(\"\")\n","    lines.append(\"ANALYSIS (drafting notes only):\")\n","    lines.append(obj[\"analysis\"])\n","    lines.append(\"\")\n","    lines.append(\"RISKS:\")\n","    for r in obj[\"risks\"]:\n","        lines.append(f\"- {r['type']} / {r['severity']}: {r['note']}\")\n","    lines.append(\"\")\n","    lines.append(\"DRAFT OUTPUT:\")\n","    lines.append(obj[\"draft_output\"])\n","    lines.append(\"\")\n","    lines.append(f\"VERIFICATION STATUS: {obj['verification_status']}\")\n","    lines.append(\"\")\n","    lines.append(\"QUESTIONS TO VERIFY:\")\n","    for x in obj[\"questions_to_verify\"]:\n","        lines.append(f\"- {x}\")\n","    lines.append(\"\")\n","    return \"\\n\".join(lines)\n","\n","level1_min_std = textwrap.dedent(f\"\"\"\\\n","{DISCLAIMER_LINE}\n","\n","Minimum Standard for Safe Level 1 (Chatbots) Use — Audit/Accounting\n","1) Use firm-approved tools/configurations; comply with firm AI policy.\n","2) Minimize/redact inputs by default; do not paste sensitive client data into prompts.\n","3) Chatbot output is draft language only; it is not audit evidence and does not perform procedures.\n","4) Require structured output: facts_provided / assumptions / open_questions / risks / Not verified.\n","5) Verify any authority-like statement (ASC/PCAOB/AICPA/firm methodology) outside the model workflow.\n","6) Maintain audit trail when AI use is material (redacted prompts/outputs + hashes + reviewer notes).\n","7) Human reviewer sign-off required before client-facing or reliance-bearing use.\n","\"\"\")\n","(DELIVERABLES_DIR / \"level1_minimum_standard.txt\").write_text(level1_min_std, encoding=\"utf-8\")\n","\n","rows = []\n","for fn in CASES:\n","    task, facts, prompt = fn()\n","    out = call_chatbot(task, prompt, facts)\n","\n","    safe_name = re.sub(r\"[^a-zA-Z0-9]+\", \"_\", task).strip(\"_\").lower()\n","    json_path = DELIVERABLES_DIR / f\"{safe_name}_output.json\"\n","    txt_path = DELIVERABLES_DIR / f\"{safe_name}_draft.txt\"\n","\n","    write_json(json_path, out)\n","    txt_path.write_text(render_txt(task, out), encoding=\"utf-8\")\n","\n","    rows.append((task, len(out.get(\"open_questions\", [])), highest_sev(out.get(\"risks\", []))))\n","\n","print(\"SUMMARY (plain text)\")\n","print(\"-\" * 96)\n","print(f\"{'CASE':68} {'#OPEN_Q':>10} {'HIGHEST_RISK':>14}\")\n","print(\"-\" * 96)\n","for c, oq, hr in rows:\n","    print(f\"{c[:68]:68} {oq:>10} {hr:>14}\")\n","print(\"-\" * 96)\n","print(\"Deliverables saved to:\", str(DELIVERABLES_DIR))"],"metadata":{"id":"Q50LQnBYcz7B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768144388939,"user_tz":360,"elapsed":41165,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"3295da2e-0f34-4015-e9c2-6ce278488aa6"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["SUMMARY (plain text)\n","------------------------------------------------------------------------------------------------\n","CASE                                                                    #OPEN_Q   HIGHEST_RISK\n","------------------------------------------------------------------------------------------------\n","Case 1 — FS Audit: Draft substantive analytics workpaper narrative            1           high\n","Case 2 — SOX/ICFR: Draft walkthrough/control narrative + draft PBC r          1           high\n","Case 3 — Tax/ASC 740: Draft UTP memo shell + provision binder reques          1           high\n","Case 4 — Teaching/Methodology: Draft staff training handout for Leve          1           high\n","------------------------------------------------------------------------------------------------\n","Deliverables saved to: /content/ai_audit_ch1_runs/run_20260111T150551Z/deliverables\n"]}]},{"cell_type":"markdown","source":["##9.USER EXERCISE"],"metadata":{"id":"3juVsof2NUJC"}},{"cell_type":"markdown","source":["###9.1.OVERVIEW"],"metadata":{"id":"0A7X8eAeNVjp"}},{"cell_type":"markdown","source":["**Cell 9: Your Turn to Practice (Interactive User Exercise with Safe Intake)**\n","\n","**What This Cell Does**\n","\n","Cell 9 shifts from demonstration to hands-on practice. This is where you get to use the AI drafting system yourself with your own scenario. The cell guides you through a safe intake process, applies the redaction tools you learned about in Cell 5, lets you choose what type of document to draft, generates the output using the same strict controls from the mini-cases, and saves your work with the same professional documentation standards.\n","\n","Think of this as moving from watching a cooking demonstration to actually preparing a dish yourself – with the instructor still present to guide you and prevent common mistakes.\n","\n","**The Safe Intake Process**\n","\n","The cell begins with a clear warning printed in capital letters: \"USER EXERCISE (SAFE INTAKE — LEVEL 1 CHATBOT DRAFTING ONLY)\" followed by explicit instructions to paste only redacted or synthetic scenarios and to avoid client identifiers, account numbers, or privileged data.\n","\n","This warning is repeated deliberately because the moment of data entry is the highest-risk moment for confidentiality breaches. When you're working quickly or focused on getting results, it's easy to forget to redact. The prominent warning creates a forcing function – you have to consciously acknowledge the confidentiality requirement before proceeding.\n","\n","The cell uses Python's input() function to pause and wait for you to type or paste your scenario. This creates an interactive moment where the notebook cannot proceed until you provide information, ensuring you engage deliberately rather than passively running cells.\n","\n","**The Memory Safety Pattern**\n","\n","Immediately after you input your text, the cell stores it in a variable with a very specific name: \"_original_in_memory_only\". The underscore prefix is a Python convention indicating this variable is internal/private. The descriptive name explicitly states its purpose and limitation – this original text exists only in computer memory during this session and is never written to any file.\n","\n","Why does this matter? If the notebook crashes, logs are reviewed, or files are shared, the original unredacted text won't be in the permanent record. Only the redacted version gets logged. This is defensive programming – designing the system to minimize harm even if something goes wrong.\n","\n","The cell even includes a comment saying \"do not write this to disk\" as a reminder to anyone who might modify the code later.\n","\n","**Seeing Redaction in Action**\n","\n","The cell calls the build_minimum_necessary() function from Cell 5, which runs your input through all the redaction patterns (emails, phones, SSNs, addresses, names) and returns sanitized facts ready to send to Claude.\n","\n","The cell then shows you two important pieces of information. First, it prints the \"removed fields summary\" in JSON format, telling you exactly what was redacted. You might see: \"2 emails removed, 1 phone number removed, 3 names detected by heuristic.\" This transparency lets you verify the redaction worked as expected and didn't miss obvious sensitive data.\n","\n","Second, it prints the sanitized facts that will actually be sent to the AI model. These appear as bullet points, making it easy to review and confirm that identifying details have been removed but the essential information remains.\n","\n","**Why this visibility matters:** You need to see what the AI is receiving. If critical context got removed by overzealous redaction, you can tell before generating the output. If sensitive information somehow survived redaction, you can catch it before it gets transmitted. This transparency checkpoint is your last chance to stop and reconsider before engaging the AI.\n","\n","**Choosing Your Output Type**\n","\n","After reviewing the sanitized facts, the cell asks you to choose what type of document you want Claude to draft: workpaper, memo, or email. These three types cover the most common professional drafting tasks in accounting and audit.\n","\n","If you enter something other than these three options (or make a typo), the cell defaults to \"memo\" – a safe, general-purpose choice. This defensive design prevents the system from breaking due to unexpected input.\n","\n","**Why these three types?**\n","\n","**Workpaper** represents formal audit documentation with specific structural requirements (Purpose, Procedure, Results, Conclusion). This is highly structured and follows audit methodology standards.\n","\n","**Memo** represents internal communication and documentation – more flexible than a workpaper but still professional. Memos document decisions, summarize issues, or provide context. They're common in tax, advisory, and complex accounting situations.\n","\n","**Email** represents client communication or team coordination. Emails need professional tone, clarity, and appropriate boundaries about what you're requesting or confirming. They're less formal than workpapers or memos but still represent the firm professionally.\n","\n","Each document type requires different drafting approaches, different tone, and different content organization. The cell provides specialized prompts for each type.\n","\n","**The Customized Prompts**\n","\n","Based on your choice, the cell constructs a specific prompt instruction for Claude.\n","\n","**For workpaper:** The prompt requests a structured narrative with the standard audit headings (Purpose, Procedure, Results, Conclusion). It emphasizes drafting from facts only, not inventing procedures or evidence, using open_questions for missing items, and keeping analysis limited to drafting notes rather than audit conclusions.\n","\n","**For email:** The prompt requests a professional client email for PBC requests or status updates, using facts only. It includes a specific instruction to avoid requesting unnecessary sensitive data and to mention secure transfer methods. This reflects real-world email best practices – you need client information, but you should request it thoughtfully and handle it securely.\n","\n","**For memo:** The prompt requests an internal memo with standard sections (purpose/context, facts, draft text, open questions). It prohibits citing standards unless provided and requires keeping analysis limited to drafting notes. This gives Claude flexibility to organize information appropriately while maintaining safe boundaries.\n","\n","All three prompts end with the same critical instruction: \"Return strict JSON only.\" This ensures consistency regardless of which document type you choose.\n","\n","**Executing Your Request**\n","\n","The cell creates a task name that includes your document type choice (like \"User Exercise — WORKPAPER draft (Level 1 Chatbots)\") and calls the same call_chatbot() function used for the mini-cases.\n","\n","This means your user exercise gets exactly the same treatment as the pre-designed scenarios: strict JSON schema validation, automated risk detection, comprehensive logging, hash generation, and audit trail creation.\n","\n","Your practice exercise isn't second-class – it receives the same professional-grade controls as the demonstration cases.\n","\n","**Saving Your Work**\n","\n","After Claude generates the output, the cell saves two files with standardized names: \"user_exercise_output.json\" (the complete structured output) and \"user_exercise_output.txt\" (the human-readable formatted version).\n","\n","These files appear in the same deliverables folder as the mini-case outputs. If you run the user exercise multiple times in the same session, each run overwrites the previous files (since the filenames are identical). This prevents clutter but means you should rename files if you want to preserve multiple attempts.\n","\n","The cell confirms the save operation by printing the paths to both files, giving you immediate confirmation that your work has been captured.\n","\n","**The Learning Through Doing**\n","\n","This interactive exercise serves multiple educational purposes beyond just generating one more output.\n","\n","**You experience the redaction process** with your own text, not just a demo. You see what gets flagged, what survives, and whether the sanitization preserves enough context for useful drafting.\n","\n","**You make choices** about document type and content, engaging actively rather than passively watching. Active learning creates stronger understanding than passive observation.\n","\n","**You see how the same framework adapts** to different document types. The underlying system (strict JSON, risk detection, logging) remains constant while the surface behavior (workpaper vs memo vs email format) changes based on your choice.\n","\n","**You create an artifact** you can actually review, critique, and potentially use (after appropriate human review and verification). This transforms the exercise from hypothetical to practical.\n","\n","**Potential Practice Scenarios**\n","\n","What should you use for your user exercise? Here are some safe, synthetic scenarios you could try:\n","\n","A revenue recognition scenario with incomplete facts about delivery terms and performance obligations – asking for a workpaper or memo draft. An IT general controls scenario where you have walkthrough notes about change management but lack details about segregation of duties – asking for an email requesting additional information. A tax provision scenario where you have summary numbers but lack supporting calculations or jurisdiction details – asking for a memo shell or document request list. A client status update scenario where fieldwork is in progress but certain items are pending – asking for an email draft.\n","\n","The key is keeping scenarios synthetic (not real client data) and deliberately incomplete (forcing Claude to use open_questions rather than inventing details).\n","\n","**What You Learn From Your Output**\n","\n","After generating your user exercise output, review the TXT file carefully and notice several things.\n","\n","**Facts provided section:** Does this accurately reflect what you input after redaction? If not, the redaction may have been too aggressive or the sanitization changed meanings.\n","\n","**Assumptions section:** What did Claude infer beyond your explicit facts? These assumptions might be reasonable or might be problematic – you need to evaluate them.\n","\n","**Open questions section:** What did Claude identify as missing or ambiguous? If this list is short, did Claude fail to recognize gaps, or did you actually provide complete information?\n","\n","**Risks section:** What automated or prompt-generated risks were flagged? Do you agree with these risk assessments? Would you add others?\n","\n","**Draft output:** Is this professionally written? Does it match the document type you requested? Does it stay within appropriate boundaries (no invented facts, no fabricated standards, no procedures you didn't describe)?\n","\n","**Questions to verify:** What does Claude think needs external verification? This list reveals what Claude recognizes as outside its capabilities.\n","\n","**Comparing Your Output to the Mini-Cases**\n","\n","You now have five outputs (four mini-cases plus your user exercise) in the deliverables folder. Compare them and notice patterns.\n","\n","Do all outputs share the same structural consistency despite different content? This demonstrates that strict JSON schema enforcement works across diverse scenarios. Do risk flags vary appropriately based on content complexity? Simple, well-defined tasks should have fewer and lower-severity risks. Do the outputs feel professionally appropriate for their document types? Workpapers should be more structured than emails, memos should be more detailed than status updates.\n","\n","This comparative analysis builds your intuition about what good AI-assisted drafting looks like across different contexts.\n","\n","**The Iterative Learning Opportunity**\n","\n","Cell 9 can be run multiple times. If your first attempt produces unsatisfying results, you can reflect on why (was your scenario too vague? did you request something beyond Level 1 capabilities? did the redaction remove too much context?), adjust your approach, and try again.\n","\n","This iterative practice – try, review, adjust, retry – mirrors real professional learning. You don't master new tools through one perfect attempt; you master them through repeated practice with reflection.\n","\n","**Transition to Final Documentation**\n","\n","After completing your user exercise, you have a full set of deliverables: four mini-case outputs demonstrating best practices across practice areas, one user exercise output showing your hands-on application, a minimum standards document establishing the safety baseline, comprehensive logs tracking every AI interaction, and risk registers documenting identified concerns.\n","\n","The next and final cell (Cell 10) will package all of this into a complete, portable audit trail that could be archived, reviewed, or used as documentation that AI was used responsibly and professionally.\n","\n","Cell 9 completes the active learning phase – you've moved from observer to practitioner, from consuming examples to creating your own, from understanding principles to applying them. Your user exercise output is evidence that you can use these tools safely and professionally within appropriate boundaries."],"metadata":{"id":"7SgqchOZNupJ"}},{"cell_type":"markdown","source":["###9.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"q65FZs56NXZp"}},{"cell_type":"code","source":["print(\"USER EXERCISE (SAFE INTAKE — LEVEL 1 CHATBOT DRAFTING ONLY)\")\n","print(\"Paste a REDACTED or SYNTHETIC scenario only. Do NOT include client identifiers, account numbers, or privileged data.\")\n","user_text = input(\"Scenario (safe): \").strip()\n","\n","_original_in_memory_only = user_text\n","\n","built = build_minimum_necessary(_original_in_memory_only)\n","print(\"\\nRemoved fields summary:\\n\", json.dumps(built[\"removed_fields\"], indent=2))\n","print(\"\\nSanitized facts to be sent to the model:\")\n","for b in built[\"sanitized_facts\"]:\n","    print(b)\n","\n","choice = input(\"\\nChoose output type: 'workpaper' or 'memo' or 'email': \").strip().lower()\n","if choice not in (\"workpaper\", \"memo\", \"email\"):\n","    choice = \"memo\"\n","\n","if choice == \"workpaper\":\n","    user_prompt = (\n","        \"Draft a structured audit workpaper narrative with headings: Purpose, Procedure, Results, Conclusion.\\n\"\n","        \"Facts only; do not invent procedures performed or evidence.\\n\"\n","        \"Use open_questions and questions_to_verify for missing items.\\n\"\n","        \"analysis must be drafting notes only.\\n\"\n","        \"Return strict JSON only.\"\n","    )\n","elif choice == \"email\":\n","    user_prompt = (\n","        \"Draft a professional client email (PBC request or status update) using facts only.\\n\"\n","        \"Avoid requesting unnecessary sensitive data; mention secure transfer.\\n\"\n","        \"analysis must be drafting notes only.\\n\"\n","        \"Return strict JSON only.\"\n","    )\n","else:\n","    user_prompt = (\n","        \"Draft an internal memo from facts only (purpose/context, facts, draft text, open questions).\\n\"\n","        \"Do not cite standards unless provided; keep Not verified.\\n\"\n","        \"analysis must be drafting notes only.\\n\"\n","        \"Return strict JSON only.\"\n","    )\n","\n","task = f\"User Exercise — {choice.upper()} draft (Level 1 Chatbots)\"\n","out = call_chatbot(task, user_prompt, built[\"sanitized_facts\"])\n","\n","json_path = DELIVERABLES_DIR / \"user_exercise_output.json\"\n","txt_path = DELIVERABLES_DIR / \"user_exercise_output.txt\"\n","write_json(json_path, out)\n","txt_path.write_text(render_txt(task, out), encoding=\"utf-8\")\n","\n","print(\"\\nSaved:\")\n","print(\" -\", str(json_path))\n","print(\" -\", str(txt_path))"],"metadata":{"id":"h8-UJrsrNZmu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768144525248,"user_tz":360,"elapsed":59757,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"8a3589a1-a552-4942-c9a3-487b541f4f63"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["USER EXERCISE (SAFE INTAKE — LEVEL 1 CHATBOT DRAFTING ONLY)\n","Paste a REDACTED or SYNTHETIC scenario only. Do NOT include client identifiers, account numbers, or privileged data.\n","Scenario (safe): annual report\n","\n","Removed fields summary:\n"," []\n","\n","Sanitized facts to be sent to the model:\n","- annual report\n","\n","Choose output type: 'workpaper' or 'memo' or 'email': memo\n","\n","Saved:\n"," - /content/ai_audit_ch1_runs/run_20260111T150551Z/deliverables/user_exercise_output.json\n"," - /content/ai_audit_ch1_runs/run_20260111T150551Z/deliverables/user_exercise_output.txt\n"]}]},{"cell_type":"markdown","source":["##10.THE AUDIT TRAIL"],"metadata":{"id":"deALRI7DNc11"}},{"cell_type":"markdown","source":["###10.1.OVERVIEW"],"metadata":{"id":"hspK-tF8Nd9D"}},{"cell_type":"markdown","source":["**Cell 10: Creating the Complete Audit Trail Package (Final Documentation and Archival)**\n","\n","**What This Cell Does**\n","\n","Cell 10 is the final step that transforms all the work you've done into a complete, portable, professionally documented package. This cell creates a comprehensive README file explaining everything about this session, generates a detailed file inventory, bundles all artifacts into a single ZIP archive, and provides you with a final checklist confirming that every required governance component is present.\n","\n","Think of this as closing out an engagement – you've done the work, now you're organizing the files, writing the summary memo, and preparing everything for archival or review. Six months from now, someone (including you) should be able to open this package and understand exactly what happened, how it was configured, and what controls were in place.\n","\n","**The AUDIT_README File: Your Session Documentation**\n","\n","The cell creates a file called \"AUDIT_README.txt\" that serves as the cover memo for the entire run. This isn't optional documentation – it's the essential narrative that makes everything else interpretable.\n","\n","The README begins with the mandatory disclaimer, immediately establishing that this work is educational and not professional advice requiring CPA review. This disclaimer appears at the top of every significant document in this notebook, creating redundant reminders that reinforce appropriate use boundaries.\n","\n","**The README then provides critical session identifiers:** the unique RUN_ID combining timestamp and configuration hash, the exact timestamp in UTC (universal coordinated time), the model name (Claude Sonnet 4.5), and the specific parameters used (temperature 0.2, max tokens 1200). These identifiers allow precise reconstruction of the session conditions.\n","\n","The CONFIG_HASH (configuration SHA256) is particularly important. This hash represents a cryptographic fingerprint of your entire configuration. If someone changes the model, adjusts the temperature, modifies the controls, or alters any setting, the hash changes. This provides tamper-evidence – you can prove whether the configuration remained constant across multiple runs or was modified between sessions.\n","\n","**Documenting Scope and Limitations**\n","\n","The README explicitly states: \"This run is Chapter 1 / Level 1 (Chatbots) only: drafting/formatting from provided facts, no verification, no audit procedures, no evidence creation.\"\n","\n","This scope statement is crucial for any potential reviewer. It establishes clear boundaries around what this notebook was designed to do and, equally important, what it was not designed to do. Someone reviewing your work six months later needs to understand that this tool is narrowly scoped to drafting assistance, not comprehensive AI-powered audit work.\n","\n","Professional services involve layered capabilities and controls. Level 1 tools require Level 1 controls. Future levels (extended context, multi-turn conversations, tool use, agentic workflows) would require progressively stronger controls. The README documents that this implementation is intentionally limited to the safest, most controlled level of AI use.\n","\n","**The Artifact Inventory**\n","\n","The README provides a numbered list explaining each type of file in the package and its purpose.\n","\n","**run_manifest.json** is described as containing run metadata, environment fingerprint, config hash, and serving as the reproducibility anchor. This file answers the question: \"What were the exact conditions of this run?\" If you need to recreate the environment or understand why results differ between runs, you start here.\n","\n","**prompts_log.jsonl** is described as containing redacted prompt/response records with hashes for traceability. This file answers: \"What was asked and what was answered?\" Each line is a complete interaction record. The hash values allow verification that logs haven't been tampered with.\n","\n","**risk_log.json** is described as containing risk register entries per deliverable. This file answers: \"What concerns were identified?\" It aggregates all risk flags across all tasks, making it easy to review risk patterns or prioritize which outputs need careful attention.\n","\n","**deliverables folder** is described as containing one strict JSON output and one TXT rendering per mini-case, plus the minimum standard document and user exercise outputs. This folder answers: \"What were the actual work products?\" It's where the substantive outputs live, separated from the governance documentation.\n","\n","This inventory serves multiple purposes. For a reviewer, it's a roadmap to the package contents. For you returning later, it's a reminder of what each file type contains. For compliance purposes, it documents that required artifacts were created and retained.\n","\n","**Safe Review Instructions**\n","\n","The README includes a \"Safe review\" section with three critical reminders for anyone examining the outputs.\n","\n","**Treat outputs as drafts and Not verified.** This reminds reviewers that every output, regardless of quality, remains unverified until a qualified human checks it. The AI's confidence level is irrelevant – verification is always required.\n","\n","**Any authority-like statement must be verified externally.** This specifically addresses the high-risk area of standards citations. If Claude mentioned ASC 606, PCAOB AS 2201, or AICPA AU-C 500, those references must be checked against authoritative sources before reliance.\n","\n","**Do not paste confidential client data; redaction is best-effort and imperfect.** This reminds reviewers that even with redaction tools, the fundamental responsibility lies with the user to exercise professional judgment about what information is safe to process through external AI services.\n","\n","These reminders transform the README from passive documentation into active guidance for safe use.\n","\n","**Reproducibility Instructions**\n","\n","The README includes specific instructions for reproducing this session: \"Re-run Cells 1–10 in order in Colab. Use run_manifest.json for model/params/config hash reference.\"\n","\n","Reproducibility is a core scientific and professional principle. If you make a claim based on analysis, others should be able to repeat your process and verify your results. In AI-assisted work, reproducibility has challenges (AI models are periodically updated, results can vary even with identical prompts at low but non-zero temperature), but documenting the process and configuration maximizes the possibility of approximate reproduction.\n","\n","The README tells a future user: \"Here's how to recreate something close to this session. Use the manifest as your reference point for configuration. Expect similar but not identical results due to AI model behavior.\"\n","\n","**Creating the File Inventory**\n","\n","After writing the README, the cell generates a complete file listing by recursively walking through the run directory and printing every file path (relative to the run directory root). This creates a table of contents showing the actual file structure.\n","\n","You'll see output like: \"run_manifest.json, prompts_log.jsonl, risk_log.json, pip_freeze.txt, deliverables/level1_minimum_standard.txt,\" and so on. This inventory confirms that all expected files were actually created and allows quick verification that nothing is missing.\n","\n","**The ZIP Archive: Creating a Portable Package**\n","\n","The cell uses Python's shutil.make_archive() function to create a ZIP file containing the entire run directory. The ZIP filename includes the RUN_ID, making it unique and traceable (like \"ai_audit_ch1_run_20260111T150551Z_11fdf22919.zip\").\n","\n","**Why create a ZIP archive?**\n","\n","**Portability:** A single file is easier to move, email, or archive than a directory with dozens of files. You can send this ZIP to a reviewer, upload it to a document management system, or archive it for retention compliance.\n","\n","**Preservation:** ZIP compression maintains file relationships, timestamps, and directory structure. Everything stays organized exactly as it was created.\n","\n","**Integrity:** While not cryptographically secured by default, the ZIP format provides basic integrity checking. If the ZIP becomes corrupted, extraction will fail rather than silently producing incorrect data.\n","\n","**Professional standard:** Zipping work products for archival or transmission is standard practice in professional services. Audit workpapers, tax returns, and advisory reports are routinely transmitted as ZIP archives.\n","\n","The cell prints the path to the created ZIP file, giving you immediate confirmation that the archive was successfully created and telling you where to find it.\n","\n","**The Final Checklist**\n","\n","The cell concludes by printing a checklist of what's included in the package: run_manifest.json, prompts_log.jsonl (redacted plus hashes), risk_log.json, deliverables (four cases plus minimum standard plus user exercise), and AUDIT_README.txt.\n","\n","This checklist serves as a final verification step. Before you consider this session complete, you can confirm that all required governance artifacts are present. If something is missing from this checklist, you know there was a problem during execution.\n","\n","The checklist also serves an educational purpose – it reinforces what comprehensive AI governance looks like. Not just \"I used AI and got an output\" but \"I used AI with this configuration, documented all interactions, logged all risks, saved all outputs in multiple formats, and created a complete audit trail.\"\n","\n","**What This Package Enables**\n","\n","With this complete package, you can now do several things that would be impossible with just raw AI outputs.\n","\n","**Quality review:** A supervisor or quality control reviewer can examine your work comprehensively. They can see what you asked, what you received, what risks were flagged, and how you configured the system. They can make informed judgments about whether AI was used appropriately.\n","\n","**Methodology documentation:** If you need to document that you used AI tools as part of an engagement, this package provides comprehensive evidence of your process and controls. You can demonstrate that you followed a governed approach rather than ad-hoc experimentation.\n","\n","**Training and knowledge transfer:** New staff learning to use AI tools can examine this package as a worked example. They can see the complete workflow from configuration through execution to documentation.\n","\n","**Retention compliance:** Many professional standards require retaining work documentation for specified periods. This package format is suitable for long-term retention in document management systems.\n","\n","**Investigation or dispute support:** If there's ever a question about what AI did or didn't do, this package provides contemporaneous documentation. You can prove what prompts were sent, what responses were received, and what controls were in place.\n","\n","**Continuous improvement:** By maintaining packages from multiple sessions, you can analyze patterns over time. Are certain types of tasks consistently generating high-risk flags? Are prompt techniques improving? Is the tool being used more efficiently?\n","\n","**The Governance Triangle: Auditability, Traceability, Reproducibility**\n","\n","This final cell completes the governance triangle that the entire notebook has been building toward.\n","\n","**Auditability:** Every significant action has been logged. Prompts, responses, risks, decisions, and configurations are documented. An auditor examining this work can verify what happened and whether appropriate controls were applied.\n","\n","**Traceability:** Every output can be traced back to its inputs through hash values. The chain of custody from user input through redaction through AI processing through output generation through file saving is completely documented. Nothing appears without a documented origin.\n","\n","**Reproducibility:** Anyone with this package and access to the same AI model can attempt to reproduce your work. They have your configuration, your prompts, your environment fingerprint, and detailed instructions. While exact reproduction may not be possible (due to AI model updates and inherent variability), approximate reproduction is feasible.\n","\n","These three properties transform AI use from a mysterious black box into a documented, reviewable process that meets professional standards.\n","\n","**Closing the Loop**\n","\n","Cell 10 brings the notebook full circle. Cell 1 established the philosophy and scope. Cells 2-7 built the infrastructure and tools. Cell 8 demonstrated the tools on prepared scenarios. Cell 9 let you practice hands-on. Cell 10 packages everything into a professional deliverable with comprehensive documentation.\n","\n","You started with education and principles. You end with a complete, documented, portable work product that embodies those principles in practice.\n","\n","**The Professional Message**\n","\n","The existence and thoroughness of this final cell sends an important message: using AI tools professionally requires investment in governance, documentation, and quality processes. The AI interaction itself (sending a prompt, receiving a response) takes seconds. The professional work of configuring appropriately, documenting thoroughly, logging comprehensively, and packaging properly takes substantially longer.\n","\n","This time ratio is correct and appropriate. The actual AI use should be a small fraction of the total effort. The majority of professional AI work is the governance wrapper around the AI interaction.\n","\n","Cell 10 completes that wrapper. You now have a ZIP archive containing everything needed to demonstrate professional, responsible, well-documented AI use in an accounting and audit context. This archive is your deliverable, your audit trail, your evidence of compliance, and your contribution to developing responsible AI practices in professional services.\n","\n","The work is complete. The documentation is comprehensive. The package is ready for review, archival, or use as a template for future sessions. This is what professional-grade AI governance looks like in practice."],"metadata":{"id":"QktoO36gNwPN"}},{"cell_type":"markdown","source":["###10.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"-qPlPvQYNhIv"}},{"cell_type":"code","source":["audit_readme = textwrap.dedent(f\"\"\"\\\n","AUDIT_README.txt\n","{DISCLAIMER_LINE}\n","\n","Run ID: {RUN_ID}\n","Timestamp (UTC): {RUN_TS}\n","Model: {MODEL}\n","Params: temperature={TEMPERATURE}, max_tokens={MAX_TOKENS}\n","Config SHA256: {CONFIG_HASH}\n","\n","This run is Chapter 1 / Level 1 (Chatbots) only:\n","- Drafting/formatting from provided facts\n","- No verification, no audit procedures, no evidence creation\n","\n","Artifacts:\n","1) run_manifest.json\n","   - Run metadata + environment fingerprint + config hash (reproducibility anchor)\n","2) prompts_log.jsonl\n","   - Redacted prompt/response records with prompt_hash and response_hash (traceability)\n","3) risk_log.json\n","   - Risk register entries per deliverable\n","4) deliverables/\n","   - One strict JSON output + one TXT rendering per mini-case\n","   - level1_minimum_standard.txt\n","   - user_exercise outputs (if run)\n","\n","Safe review:\n","- Treat outputs as drafts and Not verified.\n","- Any authority-like statement (ASC/PCAOB/AICPA/firm methodology) must be verified externally.\n","- Do not paste confidential client data; redaction is best-effort and imperfect.\n","\n","Reproducibility:\n","- Re-run Cells 1–10 in order in Colab.\n","- Use run_manifest.json for model/params/config hash reference.\n","\"\"\")\n","\n","readme_path = RUN_DIR / \"AUDIT_README.txt\"\n","readme_path.write_text(audit_readme, encoding=\"utf-8\")\n","\n","import shutil\n","zip_base = Path(\"/content\") / f\"ai_audit_ch1_run_{RUN_ID}\"\n","zip_path = shutil.make_archive(str(zip_base), \"zip\", str(RUN_DIR))\n","\n","print(\"Final file list:\")\n","for p in sorted(RUN_DIR.rglob(\"*\")):\n","    if p.is_file():\n","        print(\" -\", str(p.relative_to(RUN_DIR)))\n","\n","print(\"\\nZIP bundle created:\", zip_path)\n","print(\"\\nChecklist included:\")\n","print(\" - run_manifest.json\")\n","print(\" - prompts_log.jsonl (redacted + hashes)\")\n","print(\" - risk_log.json\")\n","print(\" - deliverables/ (4 cases + minimum standard + user exercise)\")\n","print(\" - AUDIT_README.txt\")"],"metadata":{"id":"STPTAD0YNi9b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##11.CONCLUSIONS"],"metadata":{"id":"7X2_AKt3NkAR"}},{"cell_type":"markdown","source":["**Conclusion: From Configuration to Documentation – The Complete Professional AI Pipeline**\n","\n","**The Pipeline: A Systematic Approach to Governed AI Use**\n","\n","This notebook has guided you through a complete, end-to-end pipeline for professional AI use in accounting and audit contexts. Understanding this pipeline as an integrated system – rather than as disconnected steps – is essential for translating what you've learned into real-world practice.\n","\n","**Stage 1: Foundation and Orientation (Cells 1-3)**\n","\n","The pipeline begins with clear scope definition and expectation setting. Before any technical work, you established what Level 1 AI can do (draft and format from provided facts) and what it cannot do (verify facts, perform procedures, create evidence). This orientation prevents the most common failure mode: attempting to use AI for tasks beyond its appropriate scope.\n","\n","You then configured your secure connection to Claude, selecting model parameters optimized for professional work rather than creative experimentation. The choice of low temperature (0.2) and moderate token limits (1200) reflects professional priorities: consistency over creativity, conciseness over comprehensiveness. Your API key was stored securely in Google Colab's Secrets system, never exposed in code. These foundational choices ripple through everything that follows.\n","\n","**Stage 2: Governance Infrastructure (Cells 4-6)**\n","\n","With the foundation established, the pipeline shifts to building governance mechanisms before doing any substantive AI work. This sequence is deliberate – controls first, capabilities second.\n","\n","Cell 4 created your documentation system: unique run identifiers combining timestamps and configuration hashes, comprehensive logging infrastructure capturing prompts and responses with cryptographic fingerprints, risk registers for aggregating concerns, and environment fingerprints enabling reproducibility. This infrastructure ensures that every subsequent AI interaction generates an audit trail automatically.\n","\n","Cell 5 built confidentiality protections through pattern-based redaction of emails, phone numbers, SSNs, addresses, and names. The system acknowledges its own limitations explicitly (\"redaction is best-effort and imperfect\"), placing ultimate responsibility on human judgment while providing a safety layer. The minimum-necessary builder enforces data minimization by limiting inputs to essential facts only.\n","\n","Cell 6 created the controlled AI conversation engine – the heart of the pipeline. This function enforces strict JSON schemas with nine mandatory keys in exact order, validates every response against defined rules, performs automated risk detection for missing questions and authority citations, logs all interactions with hashes for traceability, and refuses to proceed without \"Not verified\" status. This engine transforms Claude from an unpredictable creative tool into a controlled professional drafting assistant.\n","\n","**Stage 3: Demonstration Through Cases (Cells 7-8)**\n","\n","With governance infrastructure in place, the pipeline demonstrates proper use through carefully designed practice scenarios. Four mini-cases spanning different practice areas (financial statement audit, SOX/ICFR, tax and technical accounting, training development) show how the same controlled system adapts to diverse professional tasks while maintaining consistent governance.\n","\n","Each case deliberately includes incomplete facts, forcing the AI to acknowledge gaps rather than invent content. Each case prohibits citing authorities without verification, addressing the hallucination risk. Each case limits analysis to drafting choices rather than technical conclusions, maintaining appropriate scope boundaries.\n","\n","The execution phase saves outputs in dual formats – authoritative JSON for traceability and human-readable TXT for practical review. A plain-text summary table surfaces key quality metrics (number of open questions, highest risk severity) enabling rapid triage of which outputs need the most careful attention.\n","\n","**Stage 4: Hands-On Practice (Cell 9)**\n","\n","The pipeline shifts from observation to participation through an interactive user exercise. You experience the complete workflow with your own scenario: providing input while confronting the prominent confidentiality warning, seeing redaction applied to your text with transparent reporting of what was removed, choosing your desired output type and understanding how prompts adapt to different document formats, generating an output with the same strict controls applied to demonstration cases, and receiving deliverables in the same professional dual-format structure.\n","\n","This hands-on experience transforms abstract understanding into practical competence. You're no longer just understanding how the system works – you've operated it yourself successfully.\n","\n","**Stage 5: Comprehensive Documentation (Cell 10)**\n","\n","The pipeline concludes by packaging all work into a complete, portable audit trail. The AUDIT_README provides narrative documentation explaining the session's purpose, configuration, scope, artifacts, review guidance, and reproducibility instructions. The file inventory catalogs every created artifact, confirming nothing is missing. The ZIP archive bundles everything into a single file suitable for transmission, archival, or review.\n","\n","This final stage embodies professional closure: the work is complete, documented, packaged, and ready for the next stage of whatever professional process it supports – supervisor review, quality control, client delivery, or regulatory examination.\n","\n","**The Pipeline's Underlying Logic**\n","\n","Notice the pipeline's progression: define before configure, configure before build controls, build controls before demonstrate, demonstrate before practice, practice before document, document before close. Each stage depends on previous stages and enables subsequent stages.\n","\n","This ordering reflects a fundamental principle: in professional work, you must establish governance before exercising capability. The alternative – use the tool first, add controls later – creates gaps where ungoverned use occurs, outputs lack documentation, and risks go unmanaged. By building governance infrastructure before any substantive AI use, the pipeline ensures that even your first AI interaction operates under full controls.\n","\n","**Beyond This Notebook**\n","\n","The pipeline you've followed here is not specific to Claude, to Google Colab, or even to accounting and audit. It represents a general template for professional AI use: establish scope and boundaries, configure appropriately for professional rather than casual use, build governance infrastructure capturing audit trails and managing risks, demonstrate through realistic scenarios, enable hands-on practice with full controls active, and document comprehensively for accountability and reproducibility.\n","\n","As you encounter other AI tools, other use cases, or other professional contexts, you can adapt this pipeline structure. The specific implementation details change, but the underlying sequence – scope, configure, govern, demonstrate, practice, document – remains applicable.\n","\n","**The Main Lesson: Professional AI Use Is Mostly Governance, With AI Interaction as a Small Component**\n","\n","The central lesson of this notebook may surprise you: using AI professionally is not primarily about prompting skill, model selection, or output quality. Those matter, but they're secondary. Professional AI use is primarily about governance – building and maintaining systems that ensure responsible, accountable, documented use regardless of who operates the tool or what specific task is being performed.\n","\n","Consider the time allocation in this notebook. The actual AI interactions – sending prompts, receiving responses – occupy perhaps five percent of the total effort. The remaining ninety-five percent involves building logging infrastructure, implementing redaction systems, enforcing strict schemas, performing automated risk checks, validating outputs, creating dual-format deliverables, writing comprehensive documentation, and packaging complete audit trails.\n","\n","This ratio is not a bug to be optimized away. It is the correct and appropriate ratio for professional work. The governance wrapper is not overhead imposed on productive AI use – it is the essential structure that makes AI use professional rather than amateur, accountable rather than opaque, defensible rather than questionable.\n","\n","When you use AI casually for personal tasks, minimal governance is fine. When you use AI professionally for work that affects others, creates obligations, or might be scrutinized, comprehensive governance is mandatory. This notebook teaches you not just how to use AI, but how to use AI in a way that you could defend to a partner, explain to a regulator, document for quality control, and replicate for consistency.\n","\n","That capability – using AI responsibly within appropriate professional controls – is the foundational skill for the AI-enabled future of accounting and audit. You now possess it. Use it wisely, and build on it as you progress to higher capability levels in future chapters."],"metadata":{"id":"aV65a4QjNzQV"}}]}